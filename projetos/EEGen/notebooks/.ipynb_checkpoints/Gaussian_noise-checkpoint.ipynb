{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando dados sintéticos a partir da adição de ruído Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJxP7MGGCGYr",
    "outputId": "6ecc9714-a76f-4506-daba-d1f017a2af58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/Mestrado/venv_BCI/venv_BCI/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5184, 22, 1125])\n",
      "torch.Size([5184])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "X_ = torch.load('../data/processed/X_.pt')\n",
    "y_ = torch.load('../data/processed/y_.pt')\n",
    "\n",
    "noise = np.random.normal(0,1,(5184, 22, 1125))\n",
    "fake_X_ = X_ + noise\n",
    "\n",
    "fake_X_ = torch.as_tensor(fake_X_).float()\n",
    "\n",
    "real_set = TensorDataset(X_, y_)\n",
    "fake_set = TensorDataset(fake_X_, y_)\n",
    "\n",
    "print(X_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados sintéticos para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "fake_fulltrainset, fake_evalset = random_split(fake_set, [2592, 2592])\n",
    "fake_trainset, fake_testset = random_split(fake_fulltrainset, [1728, 864])\n",
    "real_fulltrainset, real_evalset = random_split(real_set, [2592, 2592])\n",
    "real_trainset, real_testset = random_split(real_fulltrainset, [1728, 864])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "n_chans = 22\n",
    "input_window_samples = 1125\n",
    "F1, D = 4, 2\n",
    "kernel_length = 64\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    "    F1=8,\n",
    "    D=2,\n",
    "    F2=F1*D,\n",
    "    kernel_length=kernel_length,\n",
    "    drop_prob=0.5\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do classificador com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.3455\u001b[0m        \u001b[32m1.4067\u001b[0m            \u001b[35m0.3299\u001b[0m        \u001b[31m1.3758\u001b[0m  0.0100  1.9494\n",
      "      2            \u001b[36m0.4317\u001b[0m        \u001b[32m1.3271\u001b[0m            \u001b[35m0.3657\u001b[0m        \u001b[31m1.2899\u001b[0m  0.0100  0.6581\n",
      "      3            \u001b[36m0.4479\u001b[0m        \u001b[32m1.2716\u001b[0m            \u001b[35m0.4028\u001b[0m        \u001b[31m1.2814\u001b[0m  0.0100  0.6625\n",
      "      4            \u001b[36m0.4653\u001b[0m        \u001b[32m1.2141\u001b[0m            \u001b[35m0.4630\u001b[0m        1.3483  0.0099  0.6587\n",
      "      5            0.4444        \u001b[32m1.2133\u001b[0m            0.4271        1.3368  0.0098  0.6585\n",
      "      6            \u001b[36m0.5457\u001b[0m        \u001b[32m1.2074\u001b[0m            \u001b[35m0.5000\u001b[0m        \u001b[31m1.1507\u001b[0m  0.0097  0.6604\n",
      "      7            \u001b[36m0.5608\u001b[0m        \u001b[32m1.1547\u001b[0m            0.4919        1.1842  0.0096  0.6567\n",
      "      8            0.5284        1.1638            0.4294        1.2296  0.0095  0.6613\n",
      "      9            0.5509        \u001b[32m1.1480\u001b[0m            0.4757        \u001b[31m1.1285\u001b[0m  0.0094  0.6580\n",
      "     10            0.5538        \u001b[32m1.1362\u001b[0m            \u001b[35m0.5058\u001b[0m        \u001b[31m1.1069\u001b[0m  0.0092  0.6599\n",
      "     11            \u001b[36m0.5822\u001b[0m        \u001b[32m1.1334\u001b[0m            \u001b[35m0.5139\u001b[0m        \u001b[31m1.0945\u001b[0m  0.0090  0.6670\n",
      "     12            \u001b[36m0.6100\u001b[0m        \u001b[32m1.1130\u001b[0m            \u001b[35m0.5336\u001b[0m        \u001b[31m1.0765\u001b[0m  0.0088  0.6660\n",
      "     13            0.5961        1.1224            \u001b[35m0.5370\u001b[0m        \u001b[31m1.0579\u001b[0m  0.0086  0.6661\n",
      "     14            0.5891        \u001b[32m1.0783\u001b[0m            0.5266        1.0787  0.0084  0.6628\n",
      "     15            0.5961        1.1102            0.5359        1.0691  0.0081  0.6622\n",
      "     16            0.6094        1.0790            0.5104        1.0824  0.0079  0.6653\n",
      "     17            0.6082        \u001b[32m1.0672\u001b[0m            0.5093        1.0750  0.0076  0.6631\n",
      "     18            0.5961        \u001b[32m1.0626\u001b[0m            0.5324        1.0934  0.0073  0.6643\n",
      "     19            0.5966        \u001b[32m1.0417\u001b[0m            0.5150        1.0806  0.0070  0.6627\n",
      "     20            \u001b[36m0.6476\u001b[0m        1.0523            \u001b[35m0.5729\u001b[0m        \u001b[31m1.0314\u001b[0m  0.0067  0.6631\n",
      "     21            0.6169        1.0559            0.5289        1.0659  0.0064  0.6685\n",
      "     22            0.6007        \u001b[32m1.0362\u001b[0m            0.5104        1.0800  0.0061  0.6718\n",
      "     23            0.5584        1.0442            0.5127        1.1236  0.0058  0.6637\n",
      "     24            \u001b[36m0.6771\u001b[0m        \u001b[32m1.0097\u001b[0m            \u001b[35m0.5914\u001b[0m        \u001b[31m0.9831\u001b[0m  0.0055  0.6384\n",
      "     25            0.6736        \u001b[32m0.9970\u001b[0m            \u001b[35m0.5926\u001b[0m        0.9877  0.0052  0.6611\n",
      "     26            0.6372        1.0267            0.5637        0.9992  0.0048  0.6704\n",
      "     27            \u001b[36m0.6817\u001b[0m        \u001b[32m0.9926\u001b[0m            \u001b[35m0.6053\u001b[0m        \u001b[31m0.9426\u001b[0m  0.0045  0.6664\n",
      "     28            0.6551        \u001b[32m0.9732\u001b[0m            0.5880        0.9752  0.0042  0.6645\n",
      "     29            \u001b[36m0.6956\u001b[0m        0.9855            \u001b[35m0.6134\u001b[0m        0.9472  0.0039  0.6635\n",
      "     30            0.6823        \u001b[32m0.9483\u001b[0m            \u001b[35m0.6227\u001b[0m        \u001b[31m0.9368\u001b[0m  0.0036  0.6629\n",
      "     31            \u001b[36m0.7025\u001b[0m        0.9727            0.6215        \u001b[31m0.9314\u001b[0m  0.0033  0.6692\n",
      "     32            0.6933        0.9635            0.6204        0.9491  0.0030  0.6575\n",
      "     33            0.6742        \u001b[32m0.9433\u001b[0m            0.6169        0.9565  0.0027  0.6712\n",
      "     34            \u001b[36m0.7112\u001b[0m        0.9527            \u001b[35m0.6331\u001b[0m        \u001b[31m0.9210\u001b[0m  0.0024  0.6721\n",
      "     35            \u001b[36m0.7153\u001b[0m        0.9561            \u001b[35m0.6389\u001b[0m        0.9261  0.0021  0.6697\n",
      "     36            \u001b[36m0.7240\u001b[0m        \u001b[32m0.9294\u001b[0m            0.6285        \u001b[31m0.9185\u001b[0m  0.0019  0.6731\n",
      "     37            \u001b[36m0.7280\u001b[0m        0.9383            \u001b[35m0.6516\u001b[0m        \u001b[31m0.9099\u001b[0m  0.0016  0.6557\n",
      "     38            0.7216        0.9333            0.6516        \u001b[31m0.9047\u001b[0m  0.0014  0.6700\n",
      "     39            0.7245        0.9358            \u001b[35m0.6562\u001b[0m        \u001b[31m0.8994\u001b[0m  0.0012  0.6671\n",
      "     40            0.7211        0.9425            0.6470        0.9009  0.0010  0.6663\n",
      "     41            0.7089        \u001b[32m0.9150\u001b[0m            0.6458        0.9000  0.0008  0.6765\n",
      "     42            0.7153        \u001b[32m0.9105\u001b[0m            0.6470        \u001b[31m0.8968\u001b[0m  0.0006  0.6762\n",
      "     43            0.7216        \u001b[32m0.9035\u001b[0m            0.6562        \u001b[31m0.8921\u001b[0m  0.0005  0.6651\n",
      "     44            0.7222        0.9162            \u001b[35m0.6574\u001b[0m        \u001b[31m0.8872\u001b[0m  0.0004  0.6687\n",
      "     45            0.7234        0.9081            0.6574        \u001b[31m0.8871\u001b[0m  0.0003  0.6664\n",
      "     46            0.7240        0.9217            0.6528        0.8885  0.0002  0.6690\n",
      "     47            0.7269        \u001b[32m0.9017\u001b[0m            0.6551        0.8877  0.0001  0.6669\n",
      "     48            0.7269        0.9026            0.6539        0.8873  0.0000  0.6737\n",
      "     49            0.7269        \u001b[32m0.8828\u001b[0m            0.6539        \u001b[31m0.8865\u001b[0m  0.0000  0.6712\n",
      "     50            0.7263        0.9047            0.6539        \u001b[31m0.8863\u001b[0m  0.0000  0.6830\n"
     ]
    }
   ],
   "source": [
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import LRScheduler\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "real_clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=predefined_split(real_testset),\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "real_clf.fit(real_trainset, y=None, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 61.30%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(real_clf.predict(real_evalset) == [y for X,y in real_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 63.50%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(real_clf.predict(fake_evalset) == [y for X,y in fake_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do classificador com dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6088\u001b[0m        \u001b[32m1.1171\u001b[0m            \u001b[35m0.5498\u001b[0m        \u001b[31m1.0168\u001b[0m  0.0100  0.6651\n",
      "      2            0.5579        \u001b[32m1.0631\u001b[0m            0.5139        1.0566  0.0100  0.6727\n",
      "      3            \u001b[36m0.6788\u001b[0m        \u001b[32m1.0559\u001b[0m            \u001b[35m0.6204\u001b[0m        \u001b[31m0.9143\u001b[0m  0.0100  0.6578\n",
      "      4            0.5735        \u001b[32m1.0319\u001b[0m            0.4907        1.1378  0.0099  0.6382\n",
      "      5            0.6615        1.0583            0.5694        0.9547  0.0098  0.6388\n",
      "      6            0.6574        \u001b[32m1.0257\u001b[0m            0.5787        0.9585  0.0097  0.6397\n",
      "      7            0.6447        \u001b[32m1.0019\u001b[0m            0.5775        0.9847  0.0096  0.6379\n",
      "      8            0.6620        1.0128            0.5579        0.9851  0.0095  0.6427\n",
      "      9            0.6157        \u001b[32m0.9940\u001b[0m            0.5787        0.9895  0.0094  0.6403\n",
      "     10            0.6238        1.0185            0.5961        0.9956  0.0092  0.6417\n",
      "     11            0.6782        \u001b[32m0.9917\u001b[0m            0.5729        0.9973  0.0090  0.6378\n",
      "     12            0.6470        \u001b[32m0.9606\u001b[0m            0.5602        1.0148  0.0088  0.6411\n",
      "     13            0.6372        0.9836            0.5197        1.0735  0.0086  0.6421\n",
      "     14            0.6406        0.9823            0.5394        1.0981  0.0084  0.6365\n",
      "     15            0.6765        0.9961            0.5868        0.9905  0.0081  0.6374\n",
      "     16            \u001b[36m0.6834\u001b[0m        0.9720            0.6123        0.9531  0.0079  0.6408\n",
      "     17            0.6771        0.9783            0.5567        1.0051  0.0076  0.6447\n",
      "     18            \u001b[36m0.6898\u001b[0m        0.9621            0.5891        0.9544  0.0073  0.6390\n",
      "     19            0.6667        0.9659            0.5775        0.9848  0.0070  0.6401\n",
      "     20            \u001b[36m0.7020\u001b[0m        \u001b[32m0.9359\u001b[0m            0.6169        0.9387  0.0067  0.6394\n",
      "     21            \u001b[36m0.7089\u001b[0m        0.9453            0.5775        0.9639  0.0064  0.6441\n",
      "     22            0.6418        0.9523            0.6030        0.9854  0.0061  0.6557\n",
      "     23            0.7083        \u001b[32m0.9295\u001b[0m            0.5995        0.9678  0.0058  0.6699\n",
      "     24            0.6557        \u001b[32m0.9278\u001b[0m            0.5463        1.0547  0.0055  0.6739\n",
      "     25            0.6944        0.9634            0.5833        0.9508  0.0052  0.6713\n",
      "     26            \u001b[36m0.7106\u001b[0m        0.9399            0.6019        0.9561  0.0048  0.6721\n",
      "     27            \u001b[36m0.7141\u001b[0m        \u001b[32m0.9216\u001b[0m            0.5880        0.9499  0.0045  0.6676\n",
      "     28            0.7002        \u001b[32m0.9085\u001b[0m            0.6065        0.9515  0.0042  0.6713\n",
      "     29            0.6997        0.9086            0.6134        0.9351  0.0039  0.6711\n",
      "     30            \u001b[36m0.7170\u001b[0m        \u001b[32m0.8978\u001b[0m            0.6146        0.9600  0.0036  0.6718\n",
      "     31            \u001b[36m0.7442\u001b[0m        \u001b[32m0.8800\u001b[0m            \u001b[35m0.6227\u001b[0m        0.9164  0.0033  0.6711\n",
      "     32            0.7402        0.9146            0.6100        \u001b[31m0.9000\u001b[0m  0.0030  0.6687\n",
      "     33            0.7263        0.9098            0.6076        0.9264  0.0027  0.6704\n",
      "     34            0.7361        \u001b[32m0.8785\u001b[0m            \u001b[35m0.6238\u001b[0m        0.9130  0.0024  0.6712\n",
      "     35            \u001b[36m0.7529\u001b[0m        0.8841            \u001b[35m0.6389\u001b[0m        \u001b[31m0.8938\u001b[0m  0.0021  0.6717\n",
      "     36            0.7350        0.8903            0.6343        0.9092  0.0019  0.6715\n",
      "     37            0.7413        0.8892            0.6366        0.9000  0.0016  0.6687\n",
      "     38            0.7407        \u001b[32m0.8507\u001b[0m            0.6273        0.9125  0.0014  0.6684\n",
      "     39            0.7500        0.8657            0.6285        0.8966  0.0012  0.6719\n",
      "     40            0.7332        0.8611            0.6088        0.9188  0.0010  0.6701\n",
      "     41            0.7454        0.8604            0.6285        0.8951  0.0008  0.6810\n",
      "     42            \u001b[36m0.7587\u001b[0m        0.8601            0.6331        \u001b[31m0.8864\u001b[0m  0.0006  0.6798\n",
      "     43            \u001b[36m0.7622\u001b[0m        0.8596            0.6354        \u001b[31m0.8846\u001b[0m  0.0005  0.6713\n",
      "     44            0.7569        \u001b[32m0.8388\u001b[0m            0.6285        0.8899  0.0004  0.6712\n",
      "     45            0.7593        \u001b[32m0.8370\u001b[0m            0.6250        0.8931  0.0003  0.6699\n",
      "     46            0.7622        \u001b[32m0.8284\u001b[0m            0.6319        0.8882  0.0002  0.6689\n",
      "     47            0.7616        \u001b[32m0.8230\u001b[0m            0.6343        0.8874  0.0001  0.6696\n",
      "     48            0.7616        0.8595            0.6331        0.8879  0.0000  0.6719\n",
      "     49            0.7610        0.8509            0.6319        0.8877  0.0000  0.6789\n",
      "     50            0.7616        0.8332            0.6343        0.8880  0.0000  0.6794\n"
     ]
    }
   ],
   "source": [
    "fake_clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=predefined_split(fake_testset),\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "fake_clf.fit(fake_trainset, y=None, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 65.35%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(fake_clf.predict(real_evalset) == [y for X,y in real_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 60.65%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(fake_clf.predict(fake_evalset) == [y for X,y in fake_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distância euclidiana entre os dados reais e sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(22, 1125)\n",
    "real = X_.view(-1, *size)\n",
    "fake = fake_X_.view(-1, *size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11171.8955)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(real-fake, 2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv_BCI",
   "language": "python",
   "name": "venv_bci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
