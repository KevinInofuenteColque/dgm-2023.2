{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRHEjKRJbNjY"
   },
   "source": [
    "## Geração de Notícias utilizando GPT-2\n",
    "\n",
    "Neste notebook iremos realizar treinamento (finetunning) do modelo GPT-2 treinado em PT-BR para gerar títulos de notícias de economia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S7_e3GBMPX_M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.11.0) (4.1.1)\n",
      "\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.4)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.27.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (from jupyter) (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (8.1.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (22.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->jupyter) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->jupyter) (3.0.9)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.8/site-packages (from jupyter-console->jupyter) (3.0.41)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from jupyter-console->jupyter) (2.11.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.2.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.10.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.13)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.13.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.13.1)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (68.2.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.0.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.7.0)\n",
      "\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (68.2.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mDEPRECATION: torch-tensorrt 1.1.0a0 has a non-standard dependency specifier torch>=1.10.0+cu113<1.11.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torch-tensorrt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn -q\n",
    "!pip install torch==1.11.0\n",
    "!pip install transformers[torch] -q\n",
    "\n",
    "!pip install accelerate -q\n",
    "\n",
    "!pip install -U jupyter\n",
    "!pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH0JtdCeE1n2",
    "outputId": "bcadb5a2-bfc9-4e60-ab72-c1aabb64906c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 24 03:04:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Quadro R...  On   | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   37C    P8    22W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH1W6YrdjNSp"
   },
   "source": [
    "# Preparação do dataset utilizando ``TextDataset``\n",
    "\n",
    "A suite do huggingface contém funções específicas para utilização de dataset textual.\n",
    "\n",
    "O conteúdo é carregado do Google Drive, e divido em conjunto de treinamento e teste sendo que 85% do conjunto é destinado a treinamento e 15% para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sG-6W1rkCmIz"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeYSdGtrBhPz",
    "outputId": "d617fb94-ccc7-4a32-f3e9-12775e736090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Na disputa loira, Devassa levou a melhor\\n', 'Espumante quer vender como cerveja\\n', 'Cinco novas marcas de cerveja na praça\\n', 'Mea culpa, contradições & mais Devassa\\n', 'Nizan Guanaes deixa o comando da Africa\\n', 'Cade vive um clima de guerra civil\\n', 'AmBev amplia fábrica no Amazonas\\n', 'Heineken se insinua na guerra das cervejas\\n', 'Brasil ganha cerveja de mosteiro\\n', 'Correção: governo estuda correção da tabela do IRPF\\n']\n",
      "141388\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"./dataset_full_preprocessed_labeled.txt\", \"r\")\n",
    "#text_file = open(\"/content/drive/MyDrive/gpt2-noticias/dataset_pos.txt\", \"r\")\n",
    "#text_file = open(\"/content/drive/MyDrive/gpt2-noticias/dataset_neg.txt\", \"r\")\n",
    "\n",
    "lines = text_file.readlines()\n",
    "print(lines[0:10])\n",
    "print(len(lines))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V36gOIOfLHvB",
    "outputId": "b354e427-1229-40b6-ed84-d6000bb60689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 120179\n",
      "Test dataset length: 21209\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#with open('recipes.json') as f:\n",
    "#    data = json.load(f)\n",
    "\n",
    "def build_text_files(data_json, dest_path):\n",
    "    f = open(dest_path, 'w')\n",
    "    data = ''\n",
    "    for texts in data_json:\n",
    "        summary = str(texts).strip()\n",
    "        summary = re.sub(r\"\\s\", \" \", summary)\n",
    "        data += summary + \"  \"\n",
    "    f.write(data)\n",
    "\n",
    "train, test = train_test_split(lines,test_size=0.15)\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'\n",
    "\n",
    "build_text_files(train,train_path)\n",
    "build_text_files(test,test_path)\n",
    "\n",
    "print(\"Train dataset length: \"+str(len(train)))\n",
    "print(\"Test dataset length: \"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg78wNnTl305"
   },
   "source": [
    "### Carregamento de tokenizador\n",
    "Para o projeto, utilizaremos o tokenizador do modelo `pierreguillou/gpt2-small-portuguese` disponível no [huggingface](https://huggingface.co/pierreguillou/gpt2-small-portuguese)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m9lHS0mIMak4"
   },
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    #train_dataset = load_dataset(\"text\", data_dir=train_path)\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    #test_dataset = load_dataset(\"text\", data_dir=test_path)\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJAqtMNLIqe1",
    "outputId": "48b48cbd-85c7-4633-a339-ff58e2cb6e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pierreguillou/gpt2-small-portuguese', '')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_from_epoch = 6\n",
    "start_from_epoch = False\n",
    "\n",
    "project_name = 'gpt2-noticias'\n",
    "\n",
    "model_name = \"pierreguillou/gpt2-small-portuguese\"\n",
    "#model_name = 'bigscience/bloom-560m'\n",
    "#model_name = 'maritaca-ai/sabia-7b'\n",
    "\n",
    "tokenizer_name = model_name\n",
    "\n",
    "#model_path = '/content/drive/MyDrive/gpt2-noticias/bigscience/bloom-560m/2023_11_21_1425'\n",
    "#model_path = '/content/drive/MyDrive/gpt2-noticias/pierreguillou/gpt2-small-portuguese/2023_10_17_0001/epoch_'+str(start_from_epoch)\n",
    "#model_path = '/content/drive/MyDrive/gpt2-noticias/pierreguillou/gpt2-small-portuguese/'\n",
    "#model_path = 'H:\\My Drive/gpt2-noticias/pierreguillou/gpt2-small-portuguese/2023_10_06_1511/epoch_'+str(start_from_epoch)\n",
    "model_path = ''\n",
    "\n",
    "(model_name, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SFy5uOlVSdZB"
   },
   "outputs": [],
   "source": [
    "if(os.path.isdir('models') == False ):\n",
    "  os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_t3--QI8sLWY",
    "outputId": "2738207d-7cd9-4d65-b017-453aa71bae11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = '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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pierreguillou/gpt2-small-portuguese\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b8W-0d5nhev",
    "outputId": "7efcd9bb-0060-438e-d92c-1a16c0e1e56c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RJsCMpCC98T"
   },
   "source": [
    "Criação de pastas para resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xr-8dFZ1lX2V",
    "outputId": "d0ec4070-8509-469b-9298-eb66722ce457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/pierreguillou/gpt2-small-portuguese/2023_11_24_0304'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "date_str = datetime.now().strftime(\"%Y_%m_%d_%H%M\")\n",
    "\n",
    "model_drive_dir = model_path\n",
    "\n",
    "if(os.path.isdir(model_drive_dir) == False):\n",
    "  model_drive_dir = os.path.join('models', model_name)\n",
    "\n",
    "if(start_from_epoch == False):\n",
    "    model_drive_dir = os.path.join(model_drive_dir, date_str)\n",
    "model_drive_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPlS33x2DPaJ"
   },
   "source": [
    "### Carregamento do modelo\n",
    "A seguir, carregamos o modelo, definimos os métodos para treinamento, geração e gravação dos títulos gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H7hhmbT2ModI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`fused_weight_gradient_mlp_cuda` module not found. gradient accumulation fusion with weight gradient computation disabled.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead,AutoModelForMaskedLM,AutoModelForCausalLM\n",
    "\n",
    "def load_model(model_name,model_drive_dir, data_collator, train_dataset, test_dataset):\n",
    "  #model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "  model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=model_drive_dir, #The output directory\n",
    "      overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "      num_train_epochs=180, # number of training epochs\n",
    "      per_device_train_batch_size=128, # batch size for training\n",
    "      per_device_eval_batch_size=256,  # batch size for evaluation\n",
    "      eval_steps = 500, # Number of update steps between two evaluations.\n",
    "      save_steps=500, # after # steps model is saved\n",
    "      warmup_steps=200,# number of warmup steps for learning rate scheduler\n",
    "      prediction_loss_only=False,\n",
    "      learning_rate=2.5e-5,\n",
    "      evaluation_strategy=\"steps\",\n",
    "      load_best_model_at_end=True,\n",
    "      auto_find_batch_size=True\n",
    "  )\n",
    "\n",
    "  return Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      data_collator=data_collator,\n",
    "      train_dataset=train_dataset,\n",
    "      eval_dataset=test_dataset,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9sAvvTSMej3Y"
   },
   "outputs": [],
   "source": [
    "def save_noticias_geradas(model_drive_dir, noticias):\n",
    "  file = open(os.path.join(model_drive_dir, 'noticias_geradas_'+date_str+'.txt'),'w+')\n",
    "\n",
    "  for n in noticias:\n",
    "    #print(n)\n",
    "    file.write(n)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "  file.close()\n",
    "\n",
    "def save_metrics(model_drive_dir, metricas):\n",
    "  file = open(os.path.join(model_drive_dir, 'metricas_'+date_str+'.txt'),'w+')\n",
    "\n",
    "  file.write(str(metricas))\n",
    "\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fh4Q1BR0OtDo"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def generate_noticias(model_drive_dir, model_name, qtde_noticias = 10, autosave = False):\n",
    "  print(\"Gerando \"+str(qtde_noticias)+\" noticias com o modelo: \"+model_drive_dir+', tokenizer='+model_name)\n",
    "  base_str =  'A  '\n",
    "  noticias = []\n",
    "\n",
    "  gerador_noticias = pipeline('text-generation', model=model_drive_dir, tokenizer=model_name, max_new_tokens=100)\n",
    "\n",
    "  while len(noticias) < qtde_noticias:\n",
    "    noticias_geradas = gerador_noticias(base_str)[0]['generated_text'].split('  ')\n",
    "    if(len(noticias_geradas) == 1):\n",
    "      noticias_geradas = gerador_noticias(base_str)[0]['generated_text'].split('.')\n",
    "    if(len(noticias)==1):\n",
    "      base_str = '  '\n",
    "      continue\n",
    "\n",
    "    for n in noticias_geradas:\n",
    "      if(len(n.strip()) < 3):\n",
    "        continue;\n",
    "      noticias.append(n.strip());\n",
    "      print(n.strip());\n",
    "\n",
    "    base_str = noticias.pop();\n",
    "\n",
    "    if autosave == True:\n",
    "      save_noticias_geradas(model_drive_dir, noticias)\n",
    "\n",
    "    print(\"Gerei \", len(noticias))\n",
    "\n",
    "  return noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyQh0jlTqR6-"
   },
   "source": [
    "## Treinamento do Modelo\n",
    "\n",
    "O modelo pode ser treinado do zero ou continuar o treinamento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKzGDT0tLSpa",
    "outputId": "d20d10c7-c0c7-4e33-e4ab-df3deba062ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/pierreguillou/gpt2-small-portuguese/2023_11_24_0304',\n",
       " 'models/pierreguillou/gpt2-small-portuguese/2023_11_24_0304/epoch_0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start_from_epoch=6\n",
    "if(start_from_epoch != False):\n",
    "    saved_model_drive_dir = os.path.join(model_drive_dir, 'epoch_'+str(start_from_epoch))\n",
    "    model_name = saved_model_drive_dir\n",
    "else:\n",
    "    saved_model_drive_dir = os.path.join(model_drive_dir, 'epoch_0')\n",
    "\n",
    "#if(os.path.isdir(model_drive_dir) == False):\n",
    "#    saved_model_drive_dir = model_name\n",
    "\n",
    "(model_drive_dir, saved_model_drive_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pgFvv3aQUtLz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = load_model(model_name,saved_model_drive_dir, data_collator, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "wjIzSWPTKzBf",
    "outputId": "d28fd0ec-323d-41fd-e9f3-b096acb477eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19440' max='19440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19440/19440 8:29:39, Epoch 180/180]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.300300</td>\n",
       "      <td>3.706860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.646900</td>\n",
       "      <td>3.532894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.457700</td>\n",
       "      <td>3.447563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.331600</td>\n",
       "      <td>3.399931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.234900</td>\n",
       "      <td>3.367739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.153900</td>\n",
       "      <td>3.345399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.083100</td>\n",
       "      <td>3.332832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.022100</td>\n",
       "      <td>3.324341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.964600</td>\n",
       "      <td>3.316356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.914600</td>\n",
       "      <td>3.317461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.866600</td>\n",
       "      <td>3.315511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.821900</td>\n",
       "      <td>3.320138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.781200</td>\n",
       "      <td>3.327271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.742500</td>\n",
       "      <td>3.327224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.706800</td>\n",
       "      <td>3.336920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.673300</td>\n",
       "      <td>3.342765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.641100</td>\n",
       "      <td>3.347899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.610600</td>\n",
       "      <td>3.356383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.583500</td>\n",
       "      <td>3.363745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.556700</td>\n",
       "      <td>3.369778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.531300</td>\n",
       "      <td>3.380662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.509100</td>\n",
       "      <td>3.384252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.487500</td>\n",
       "      <td>3.391420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.467200</td>\n",
       "      <td>3.398602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.448000</td>\n",
       "      <td>3.404943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.431000</td>\n",
       "      <td>3.411084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.415800</td>\n",
       "      <td>3.417698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.423741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.387700</td>\n",
       "      <td>3.426764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.374900</td>\n",
       "      <td>3.432011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.363900</td>\n",
       "      <td>3.438550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.354400</td>\n",
       "      <td>3.440667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.346000</td>\n",
       "      <td>3.444038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.338400</td>\n",
       "      <td>3.445951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.332700</td>\n",
       "      <td>3.447504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.327600</td>\n",
       "      <td>3.450351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.323600</td>\n",
       "      <td>3.451319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.321300</td>\n",
       "      <td>3.452419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/pierreguillou/gpt2-small-portuguese/2023_11_24_0304/epoch_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3155109882354736, 'eval_runtime': 10.0229, 'eval_samples_per_second': 242.244, 'eval_steps_per_second': 0.998, 'epoch': 180.0}\n"
     ]
    }
   ],
   "source": [
    "#for i in range(start_from_epoch+1,start_from_epoch+2):\n",
    "i=2\n",
    "\n",
    "iteration_model_path = os.path.join(model_drive_dir, \"epoch_\" + str(i))\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Saving model to: \"+iteration_model_path)\n",
    "trainer.save_model (iteration_model_path)\n",
    "\n",
    "metrics = str(trainer.evaluate())\n",
    "print(metrics)\n",
    "save_metrics(iteration_model_path, metrics)\n",
    "\n",
    "#noticias = generate_noticias(iteration_model_path, model_name, 50)\n",
    "#save_noticias_geradas(iteration_model_path, noticias)\n",
    "\n",
    "start_from_epoch=start_from_epoch + 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
