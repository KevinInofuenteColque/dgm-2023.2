{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2Zq4vte7Kmb"
   },
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/Mestrado/venv_BCI/venv_BCI/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 1, 22, 1125])\n",
      "torch.Size([1296, 1, 22, 1125])\n",
      "torch.Size([1296, 1, 22, 1125])\n",
      "torch.Size([1296, 1, 22, 1125])\n",
      "torch.Size([5184, 22, 1125])\n",
      "torch.Size([5184])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "X_ = torch.load('../data/processed/X_.pt')\n",
    "y_ = torch.load('../data/processed/y_.pt')\n",
    "\n",
    "real_set = TensorDataset(X_, y_)\n",
    "\n",
    "X_0 = torch.load('../data/processed/X_0.pt')\n",
    "X_1 = torch.load('../data/processed/X_1.pt')\n",
    "X_2 = torch.load('../data/processed/X_2.pt')\n",
    "X_3 = torch.load('../data/processed/X_3.pt')\n",
    "\n",
    "X_0 = torch.from_numpy(np.expand_dims(X_0, axis=1))\n",
    "X_1 = torch.from_numpy(np.expand_dims(X_1, axis=1))\n",
    "X_2 = torch.from_numpy(np.expand_dims(X_2, axis=1))\n",
    "X_3 = torch.from_numpy(np.expand_dims(X_3, axis=1))\n",
    "\n",
    "gen_set_0 = TensorDataset(X_0, torch.as_tensor(np.full(1296, 0)))\n",
    "gen_set_1 = TensorDataset(X_1, torch.as_tensor(np.full(1296, 1)))\n",
    "gen_set_2 = TensorDataset(X_2, torch.as_tensor(np.full(1296, 2)))\n",
    "gen_set_3 = TensorDataset(X_3, torch.as_tensor(np.full(1296, 3)))\n",
    "\n",
    "print(X_0.shape)\n",
    "print(X_1.shape)\n",
    "print(X_2.shape)\n",
    "print(X_3.shape)\n",
    "print(X_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo da GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import flatten\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inputDim=100, outputChannels=1):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.ct1 = nn.ConvTranspose2d(in_channels=inputDim, out_channels=128, kernel_size=(1, 140), stride=2, padding=0, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batchNorm1 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.ct2 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(4, 4), stride=2, padding=0, bias=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchNorm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.ct3 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(4, 1), stride=2, padding=0, bias=False)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.batchNorm3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.ct4 = nn.ConvTranspose2d(in_channels=32, out_channels=outputChannels, kernel_size=(4, 1), stride=2, padding=0, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ct1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batchNorm1(x)\n",
    "        \n",
    "        x = self.ct2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchNorm2(x)\n",
    "        \n",
    "        x = self.ct3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.batchNorm3(x)\n",
    "        \n",
    "        x = self.ct4(x)\n",
    "        output = self.tanh(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self, depth, alpha=0.2):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "        \n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=depth, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "\t\tself.leakyRelu1 = nn.LeakyReLU(alpha, inplace=True)\n",
    "        \n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "\t\tself.leakyRelu2 = nn.LeakyReLU(alpha, inplace=True)\n",
    "        \n",
    "\t\tself.fc1 = nn.Linear(in_features=89920, out_features=512)\n",
    "\t\tself.leakyRelu3 = nn.LeakyReLU(alpha, inplace=True)\n",
    "        \n",
    "\t\tself.fc2 = nn.Linear(in_features=512, out_features=1)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.leakyRelu1(x)\n",
    "        \n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.leakyRelu2(x)\n",
    "        \n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.leakyRelu3(x)\n",
    "        \n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.sigmoid(x)\n",
    "        \n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_0 = DataLoader(dataset=gen_set_0, batch_size=128)\n",
    "dataloader_1 = DataLoader(dataset=gen_set_1, batch_size=128)\n",
    "dataloader_2 = DataLoader(dataset=gen_set_2, batch_size=128)\n",
    "dataloader_3 = DataLoader(dataset=gen_set_3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building generator...\n",
      "[INFO] building discriminator...\n",
      "[INFO] starting training...\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "stepsPerEpoch = len(dataloader_0.dataset) // BATCH_SIZE\n",
    "\n",
    "print(\"[INFO] building generator...\")\n",
    "gen = Generator(inputDim=100, outputChannels=1)\n",
    "gen.to(DEVICE)\n",
    "\n",
    "print(\"[INFO] building discriminator...\")\n",
    "disc = Discriminator(depth=1)\n",
    "disc.to(DEVICE)\n",
    "\n",
    "genOpt = Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=0.0002 / NUM_EPOCHS)\n",
    "discOpt = Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=0.0002 / NUM_EPOCHS)\n",
    "\n",
    "criterion = BCELoss()\n",
    "\n",
    "print(\"[INFO] starting training...\")\n",
    "benchmarkNoise = torch.randn(1296, 100, 1, 1, device=DEVICE)\n",
    "\n",
    "realLabel = 1\n",
    "fakeLabel = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração dos dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1 of 20...\n",
      "[INFO] Generator Loss: 6.5883, Discriminator Loss: 0.5440\n",
      "[INFO] starting epoch 2 of 20...\n",
      "[INFO] Generator Loss: 6.9375, Discriminator Loss: 0.0082\n",
      "[INFO] starting epoch 3 of 20...\n",
      "[INFO] Generator Loss: 6.3571, Discriminator Loss: 0.0169\n",
      "[INFO] starting epoch 4 of 20...\n",
      "[INFO] Generator Loss: 8.2464, Discriminator Loss: 0.0015\n",
      "[INFO] starting epoch 5 of 20...\n",
      "[INFO] Generator Loss: 8.6315, Discriminator Loss: 0.0011\n",
      "[INFO] starting epoch 6 of 20...\n",
      "[INFO] Generator Loss: 8.6627, Discriminator Loss: 0.0009\n",
      "[INFO] starting epoch 7 of 20...\n",
      "[INFO] Generator Loss: 9.6442, Discriminator Loss: 0.0004\n",
      "[INFO] starting epoch 8 of 20...\n",
      "[INFO] Generator Loss: 10.1951, Discriminator Loss: 0.0003\n",
      "[INFO] starting epoch 9 of 20...\n",
      "[INFO] Generator Loss: 10.6040, Discriminator Loss: 0.0002\n",
      "[INFO] starting epoch 10 of 20...\n",
      "[INFO] Generator Loss: 10.4195, Discriminator Loss: 0.0002\n",
      "[INFO] starting epoch 11 of 20...\n",
      "[INFO] Generator Loss: 10.4494, Discriminator Loss: 0.0002\n",
      "[INFO] starting epoch 12 of 20...\n",
      "[INFO] Generator Loss: 10.9099, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 13 of 20...\n",
      "[INFO] Generator Loss: 11.2470, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 14 of 20...\n",
      "[INFO] Generator Loss: 11.5548, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 15 of 20...\n",
      "[INFO] Generator Loss: 11.7748, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 16 of 20...\n",
      "[INFO] Generator Loss: 11.9666, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 17 of 20...\n",
      "[INFO] Generator Loss: 12.1012, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 18 of 20...\n",
      "[INFO] Generator Loss: 12.1847, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 19 of 20...\n",
      "[INFO] Generator Loss: 12.1445, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 20 of 20...\n",
      "[INFO] Generator Loss: 11.8358, Discriminator Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    epochLossG = 0\n",
    "    epochLossD = 0\n",
    "    for x in dataloader_0:\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        images = x[0]\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        bs =  images.size(0)\n",
    "        labels = torch.full((bs,), realLabel, dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "        output = disc(images).view(-1)\n",
    "        \n",
    "        errorReal = criterion(output, labels)\n",
    "        \n",
    "        errorReal.backward()\n",
    "        \n",
    "        noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "        \n",
    "        fake_0 = gen(noise)\n",
    "        labels.fill_(fakeLabel)\n",
    "        \n",
    "        output = disc(fake_0.detach()).view(-1)\n",
    "        errorFake = criterion(output, labels)\n",
    "        \n",
    "        errorFake.backward()\n",
    "        \n",
    "        errorD = errorReal + errorFake\n",
    "        discOpt.step()\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        \n",
    "        labels.fill_(realLabel)\n",
    "        output = disc(fake_0).view(-1)\n",
    "        \n",
    "        errorG = criterion(output, labels)\n",
    "        errorG.backward()\n",
    "        \n",
    "        genOpt.step()\n",
    "        \n",
    "        epochLossD += errorD\n",
    "        epochLossG += errorG\n",
    "        \n",
    "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        gen.eval()\n",
    "        fake_0 = gen(benchmarkNoise)\n",
    "        gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 1, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "print(fake_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "size=(22, 1125)\n",
    "fake_0 = fake_0.detach().cpu().view(-1, *size)\n",
    "print(fake_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1 of 20...\n",
      "[INFO] Generator Loss: 11.2221, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 2 of 20...\n",
      "[INFO] Generator Loss: 10.7367, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 3 of 20...\n",
      "[INFO] Generator Loss: 10.5085, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 4 of 20...\n",
      "[INFO] Generator Loss: 10.4779, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 5 of 20...\n",
      "[INFO] Generator Loss: 10.4281, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 6 of 20...\n",
      "[INFO] Generator Loss: 10.8077, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 7 of 20...\n",
      "[INFO] Generator Loss: 11.1647, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 8 of 20...\n",
      "[INFO] Generator Loss: 11.4017, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 9 of 20...\n",
      "[INFO] Generator Loss: 11.6652, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 10 of 20...\n",
      "[INFO] Generator Loss: 11.8915, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 11 of 20...\n",
      "[INFO] Generator Loss: 12.0710, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 12 of 20...\n",
      "[INFO] Generator Loss: 12.2140, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 13 of 20...\n",
      "[INFO] Generator Loss: 12.3323, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 14 of 20...\n",
      "[INFO] Generator Loss: 12.4053, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 15 of 20...\n",
      "[INFO] Generator Loss: 12.4319, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 16 of 20...\n",
      "[INFO] Generator Loss: 12.4073, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 17 of 20...\n",
      "[INFO] Generator Loss: 11.1000, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 18 of 20...\n",
      "[INFO] Generator Loss: 10.9170, Discriminator Loss: 0.0001\n",
      "[INFO] starting epoch 19 of 20...\n",
      "[INFO] Generator Loss: 11.7251, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 20 of 20...\n",
      "[INFO] Generator Loss: 12.1520, Discriminator Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    epochLossG = 0\n",
    "    epochLossD = 0\n",
    "    for x in dataloader_1:\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        images = x[0]\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        bs =  images.size(0)\n",
    "        labels = torch.full((bs,), realLabel, dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "        output = disc(images).view(-1)\n",
    "        \n",
    "        errorReal = criterion(output, labels)\n",
    "        \n",
    "        errorReal.backward()\n",
    "        \n",
    "        noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "        \n",
    "        fake_1 = gen(noise)\n",
    "        labels.fill_(fakeLabel)\n",
    "        \n",
    "        output = disc(fake_1.detach()).view(-1)\n",
    "        errorFake = criterion(output, labels)\n",
    "        \n",
    "        errorFake.backward()\n",
    "        \n",
    "        errorD = errorReal + errorFake\n",
    "        discOpt.step()\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        \n",
    "        labels.fill_(realLabel)\n",
    "        output = disc(fake_1).view(-1)\n",
    "        \n",
    "        errorG = criterion(output, labels)\n",
    "        errorG.backward()\n",
    "        \n",
    "        genOpt.step()\n",
    "        \n",
    "        epochLossD += errorD\n",
    "        epochLossG += errorG\n",
    "        \n",
    "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        gen.eval()\n",
    "        fake_1 = gen(benchmarkNoise)\n",
    "        gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 1, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "print(fake_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "fake_1 = fake_1.detach().cpu().view(-1, *size)\n",
    "print(fake_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1 of 20...\n",
      "[INFO] Generator Loss: 12.4943, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 2 of 20...\n",
      "[INFO] Generator Loss: 12.7471, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 3 of 20...\n",
      "[INFO] Generator Loss: 12.9096, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 4 of 20...\n",
      "[INFO] Generator Loss: 13.0524, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 5 of 20...\n",
      "[INFO] Generator Loss: 13.1832, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 6 of 20...\n",
      "[INFO] Generator Loss: 13.3301, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 7 of 20...\n",
      "[INFO] Generator Loss: 13.4495, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 8 of 20...\n",
      "[INFO] Generator Loss: 13.5171, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 9 of 20...\n",
      "[INFO] Generator Loss: 13.5830, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 10 of 20...\n",
      "[INFO] Generator Loss: 13.6201, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 11 of 20...\n",
      "[INFO] Generator Loss: 13.7459, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 12 of 20...\n",
      "[INFO] Generator Loss: 13.8642, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 13 of 20...\n",
      "[INFO] Generator Loss: 13.9659, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 14 of 20...\n",
      "[INFO] Generator Loss: 14.0570, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 15 of 20...\n",
      "[INFO] Generator Loss: 14.1339, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 16 of 20...\n",
      "[INFO] Generator Loss: 14.1901, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 17 of 20...\n",
      "[INFO] Generator Loss: 14.2701, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 18 of 20...\n",
      "[INFO] Generator Loss: 14.3461, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 19 of 20...\n",
      "[INFO] Generator Loss: 14.4236, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 20 of 20...\n",
      "[INFO] Generator Loss: 14.4847, Discriminator Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    epochLossG = 0\n",
    "    epochLossD = 0\n",
    "    for x in dataloader_2:\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        images = x[0]\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        bs =  images.size(0)\n",
    "        labels = torch.full((bs,), realLabel, dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "        output = disc(images).view(-1)\n",
    "        \n",
    "        errorReal = criterion(output, labels)\n",
    "        \n",
    "        errorReal.backward()\n",
    "        \n",
    "        noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "        \n",
    "        fake_2 = gen(noise)\n",
    "        labels.fill_(fakeLabel)\n",
    "        \n",
    "        output = disc(fake_2.detach()).view(-1)\n",
    "        errorFake = criterion(output, labels)\n",
    "        \n",
    "        errorFake.backward()\n",
    "        \n",
    "        errorD = errorReal + errorFake\n",
    "        discOpt.step()\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        \n",
    "        labels.fill_(realLabel)\n",
    "        output = disc(fake_2).view(-1)\n",
    "        \n",
    "        errorG = criterion(output, labels)\n",
    "        errorG.backward()\n",
    "        \n",
    "        genOpt.step()\n",
    "        \n",
    "        epochLossD += errorD\n",
    "        epochLossG += errorG\n",
    "        \n",
    "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        gen.eval()\n",
    "        fake_2 = gen(benchmarkNoise)\n",
    "        gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 1, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "print(fake_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "fake_2 = fake_2.detach().cpu().view(-1, *size)\n",
    "print(fake_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1 of 20...\n",
      "[INFO] Generator Loss: 14.5325, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 2 of 20...\n",
      "[INFO] Generator Loss: 14.5642, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 3 of 20...\n",
      "[INFO] Generator Loss: 14.6097, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 4 of 20...\n",
      "[INFO] Generator Loss: 14.6546, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 5 of 20...\n",
      "[INFO] Generator Loss: 14.6978, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 6 of 20...\n",
      "[INFO] Generator Loss: 14.7417, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 7 of 20...\n",
      "[INFO] Generator Loss: 14.7856, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 8 of 20...\n",
      "[INFO] Generator Loss: 14.8293, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 9 of 20...\n",
      "[INFO] Generator Loss: 14.8658, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 10 of 20...\n",
      "[INFO] Generator Loss: 14.9002, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 11 of 20...\n",
      "[INFO] Generator Loss: 14.9376, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 12 of 20...\n",
      "[INFO] Generator Loss: 14.9740, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 13 of 20...\n",
      "[INFO] Generator Loss: 15.0080, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 14 of 20...\n",
      "[INFO] Generator Loss: 15.0376, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 15 of 20...\n",
      "[INFO] Generator Loss: 15.0712, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 16 of 20...\n",
      "[INFO] Generator Loss: 15.1005, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 17 of 20...\n",
      "[INFO] Generator Loss: 15.1275, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 18 of 20...\n",
      "[INFO] Generator Loss: 15.1564, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 19 of 20...\n",
      "[INFO] Generator Loss: 15.1827, Discriminator Loss: 0.0000\n",
      "[INFO] starting epoch 20 of 20...\n",
      "[INFO] Generator Loss: 15.2071, Discriminator Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    epochLossG = 0\n",
    "    epochLossD = 0\n",
    "    for x in dataloader_3:\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        images = x[0]\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        bs =  images.size(0)\n",
    "        labels = torch.full((bs,), realLabel, dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "        output = disc(images).view(-1)\n",
    "        \n",
    "        errorReal = criterion(output, labels)\n",
    "        \n",
    "        errorReal.backward()\n",
    "        \n",
    "        noise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
    "        \n",
    "        fake_3 = gen(noise)\n",
    "        labels.fill_(fakeLabel)\n",
    "        \n",
    "        output = disc(fake_3.detach()).view(-1)\n",
    "        errorFake = criterion(output, labels)\n",
    "        \n",
    "        errorFake.backward()\n",
    "        \n",
    "        errorD = errorReal + errorFake\n",
    "        discOpt.step()\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        \n",
    "        labels.fill_(realLabel)\n",
    "        output = disc(fake_3).view(-1)\n",
    "        \n",
    "        errorG = criterion(output, labels)\n",
    "        errorG.backward()\n",
    "        \n",
    "        genOpt.step()\n",
    "        \n",
    "        epochLossD += errorD\n",
    "        epochLossG += errorG\n",
    "        \n",
    "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        gen.eval()\n",
    "        fake_3 = gen(benchmarkNoise)\n",
    "        gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 1, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "print(fake_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1296, 22, 1125])\n"
     ]
    }
   ],
   "source": [
    "fake_3 = fake_3.detach().cpu().view(-1, *size)\n",
    "print(fake_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.cpu()\n",
    "disc.cpu()\n",
    "del gen, disc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados sintéticos para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5184, 22, 1125])\n",
      "torch.Size([5184])\n"
     ]
    }
   ],
   "source": [
    "fake = torch.cat((fake_0, fake_1, fake_2, fake_3), 0)\n",
    "y_fake = torch.cat((torch.as_tensor(np.full(1296, 0)), torch.as_tensor(np.full(1296, 1)), torch.as_tensor(np.full(1296, 2)), torch.as_tensor(np.full(1296, 3))), 0)\n",
    "print(fake.shape)\n",
    "print(y_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_set = TensorDataset(fake, y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "fake_fulltrainset, fake_evalset = random_split(fake_set, [2592, 2592])\n",
    "fake_trainset, fake_testset = random_split(fake_fulltrainset, [1728, 864])\n",
    "real_fulltrainset, real_evalset = random_split(real_set, [2592, 2592])\n",
    "real_trainset, real_testset = random_split(real_fulltrainset, [1728, 864])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "n_chans = 22\n",
    "input_window_samples = 1125\n",
    "F1, D = 4, 2\n",
    "kernel_length = 64\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    "    F1=8,\n",
    "    D=2,\n",
    "    F2=F1*D,\n",
    "    kernel_length=kernel_length,\n",
    "    drop_prob=0.5\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do classificador com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.3791\u001b[0m        \u001b[32m1.4077\u001b[0m            \u001b[35m0.3345\u001b[0m        \u001b[31m1.3455\u001b[0m  0.0100  0.7004\n",
      "      2            \u001b[36m0.3981\u001b[0m        \u001b[32m1.3305\u001b[0m            \u001b[35m0.3519\u001b[0m        1.3692  0.0100  0.6654\n",
      "      3            \u001b[36m0.4728\u001b[0m        \u001b[32m1.2907\u001b[0m            \u001b[35m0.4039\u001b[0m        \u001b[31m1.2703\u001b[0m  0.0100  0.6891\n",
      "      4            0.4363        \u001b[32m1.2580\u001b[0m            0.3877        1.4141  0.0099  0.6702\n",
      "      5            \u001b[36m0.4896\u001b[0m        \u001b[32m1.2370\u001b[0m            \u001b[35m0.4282\u001b[0m        1.2771  0.0098  0.6630\n",
      "      6            \u001b[36m0.5272\u001b[0m        \u001b[32m1.2070\u001b[0m            \u001b[35m0.4664\u001b[0m        \u001b[31m1.1793\u001b[0m  0.0097  0.6683\n",
      "      7            \u001b[36m0.5353\u001b[0m        \u001b[32m1.1885\u001b[0m            \u001b[35m0.5058\u001b[0m        \u001b[31m1.1672\u001b[0m  0.0096  0.6665\n",
      "      8            \u001b[36m0.5515\u001b[0m        \u001b[32m1.1612\u001b[0m            0.4931        \u001b[31m1.1257\u001b[0m  0.0095  0.6686\n",
      "      9            0.5353        \u001b[32m1.1422\u001b[0m            0.4954        1.1647  0.0094  0.6671\n",
      "     10            \u001b[36m0.5521\u001b[0m        1.1529            0.4965        1.1340  0.0092  0.6655\n",
      "     11            \u001b[36m0.5764\u001b[0m        1.1471            \u001b[35m0.5347\u001b[0m        \u001b[31m1.0880\u001b[0m  0.0090  0.6716\n",
      "     12            0.5671        1.1465            0.5150        1.1413  0.0088  0.6757\n",
      "     13            \u001b[36m0.5914\u001b[0m        \u001b[32m1.1026\u001b[0m            0.5058        \u001b[31m1.0865\u001b[0m  0.0086  0.6839\n",
      "     14            0.5486        1.1088            0.4965        1.1533  0.0084  0.6719\n",
      "     15            0.5503        \u001b[32m1.0869\u001b[0m            0.4711        1.1532  0.0081  0.6736\n",
      "     16            0.5596        1.1014            0.4792        1.1105  0.0079  0.6705\n",
      "     17            0.5862        1.0930            0.4942        1.1507  0.0076  0.6724\n",
      "     18            \u001b[36m0.6233\u001b[0m        \u001b[32m1.0866\u001b[0m            \u001b[35m0.5359\u001b[0m        \u001b[31m1.0758\u001b[0m  0.0073  0.6733\n",
      "     19            0.5446        1.0961            0.5000        1.1410  0.0070  0.6715\n",
      "     20            0.6198        \u001b[32m1.0853\u001b[0m            0.5289        1.0918  0.0067  0.6727\n",
      "     21            0.6047        \u001b[32m1.0659\u001b[0m            0.5150        1.0943  0.0064  0.6732\n",
      "     22            0.5966        \u001b[32m1.0658\u001b[0m            0.5058        1.0867  0.0061  0.6732\n",
      "     23            \u001b[36m0.6302\u001b[0m        1.0693            \u001b[35m0.5590\u001b[0m        \u001b[31m1.0593\u001b[0m  0.0058  0.6749\n",
      "     24            \u001b[36m0.6406\u001b[0m        \u001b[32m1.0541\u001b[0m            0.5486        \u001b[31m1.0436\u001b[0m  0.0055  0.6809\n",
      "     25            \u001b[36m0.6557\u001b[0m        \u001b[32m1.0332\u001b[0m            0.5556        \u001b[31m1.0266\u001b[0m  0.0052  0.6750\n",
      "     26            0.6100        1.0489            0.5289        1.0630  0.0048  0.6742\n",
      "     27            0.5660        1.0492            0.5197        1.0868  0.0045  0.6746\n",
      "     28            \u001b[36m0.6568\u001b[0m        \u001b[32m1.0062\u001b[0m            0.5532        \u001b[31m1.0245\u001b[0m  0.0042  0.6720\n",
      "     29            0.6348        1.0351            0.5498        1.0524  0.0039  0.6718\n",
      "     30            0.6377        \u001b[32m1.0011\u001b[0m            \u001b[35m0.5613\u001b[0m        1.0330  0.0036  0.6718\n",
      "     31            \u001b[36m0.6678\u001b[0m        \u001b[32m0.9960\u001b[0m            \u001b[35m0.5718\u001b[0m        \u001b[31m0.9907\u001b[0m  0.0033  0.6724\n",
      "     32            \u001b[36m0.6973\u001b[0m        \u001b[32m0.9945\u001b[0m            0.5613        0.9945  0.0030  0.6731\n",
      "     33            0.6771        \u001b[32m0.9753\u001b[0m            \u001b[35m0.5787\u001b[0m        0.9953  0.0027  0.6713\n",
      "     34            0.6794        \u001b[32m0.9723\u001b[0m            \u001b[35m0.5799\u001b[0m        0.9966  0.0024  0.6830\n",
      "     35            0.6834        \u001b[32m0.9556\u001b[0m            \u001b[35m0.5938\u001b[0m        \u001b[31m0.9753\u001b[0m  0.0021  0.6761\n",
      "     36            0.6950        1.0037            0.5787        0.9810  0.0019  0.6845\n",
      "     37            0.6881        0.9832            0.5833        0.9816  0.0016  0.6747\n",
      "     38            \u001b[36m0.6979\u001b[0m        \u001b[32m0.9437\u001b[0m            \u001b[35m0.5995\u001b[0m        0.9840  0.0014  0.6740\n",
      "     39            \u001b[36m0.7078\u001b[0m        0.9548            \u001b[35m0.6007\u001b[0m        \u001b[31m0.9543\u001b[0m  0.0012  0.6751\n",
      "     40            0.6985        0.9571            0.5972        0.9581  0.0010  0.6798\n",
      "     41            0.6979        \u001b[32m0.9404\u001b[0m            \u001b[35m0.6111\u001b[0m        \u001b[31m0.9472\u001b[0m  0.0008  0.6759\n",
      "     42            0.7072        0.9585            0.6088        0.9526  0.0006  0.6821\n",
      "     43            0.7014        \u001b[32m0.9367\u001b[0m            0.6053        0.9487  0.0005  0.6792\n",
      "     44            0.7049        \u001b[32m0.9271\u001b[0m            \u001b[35m0.6123\u001b[0m        0.9492  0.0004  0.6770\n",
      "     45            \u001b[36m0.7141\u001b[0m        0.9758            \u001b[35m0.6192\u001b[0m        \u001b[31m0.9463\u001b[0m  0.0003  0.6749\n",
      "     46            0.7141        0.9279            0.6181        0.9471  0.0002  0.6756\n",
      "     47            \u001b[36m0.7176\u001b[0m        0.9523            \u001b[35m0.6215\u001b[0m        \u001b[31m0.9461\u001b[0m  0.0001  0.6812\n",
      "     48            0.7130        \u001b[32m0.9224\u001b[0m            0.6169        \u001b[31m0.9453\u001b[0m  0.0000  0.6783\n",
      "     49            0.7130        0.9423            0.6157        0.9454  0.0000  0.6826\n",
      "     50            0.7130        0.9411            0.6146        0.9458  0.0000  0.6782\n"
     ]
    }
   ],
   "source": [
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import LRScheduler\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "real_clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=predefined_split(real_testset),\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "real_clf.fit(real_trainset, y=None, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 59.38%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(real_clf.predict(real_evalset) == [y for X,y in real_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 25.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(real_clf.predict(fake_evalset) == [y for X,y in fake_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do classificador com dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.2419\u001b[0m        \u001b[32m0.1274\u001b[0m            \u001b[35m0.2662\u001b[0m        \u001b[31m2.6020\u001b[0m  0.0100  0.7219\n",
      "      2            0.2419        \u001b[32m0.0004\u001b[0m            0.2662        4.2445  0.0100  0.6852\n",
      "      3            0.2419        0.0006            0.2662        4.5083  0.0100  0.6943\n",
      "      4            0.2419        \u001b[32m0.0003\u001b[0m            0.2662        4.4194  0.0099  0.6826\n",
      "      5            \u001b[36m0.4821\u001b[0m        \u001b[32m0.0001\u001b[0m            \u001b[35m0.5347\u001b[0m        3.8980  0.0098  0.6734\n",
      "      6            0.4821        0.0001            0.5347        3.2590  0.0097  0.6748\n",
      "      7            0.4821        \u001b[32m0.0001\u001b[0m            0.5347        \u001b[31m2.4245\u001b[0m  0.0096  0.6756\n",
      "      8            \u001b[36m0.7459\u001b[0m        0.0001            \u001b[35m0.7558\u001b[0m        \u001b[31m1.4161\u001b[0m  0.0095  0.6745\n",
      "      9            \u001b[36m0.7483\u001b[0m        \u001b[32m0.0000\u001b[0m            0.7558        \u001b[31m0.4941\u001b[0m  0.0094  0.6764\n",
      "     10            \u001b[36m1.0000\u001b[0m        0.0001            \u001b[35m1.0000\u001b[0m        \u001b[31m0.0477\u001b[0m  0.0092  0.6738\n",
      "     11            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0007\u001b[0m  0.0090  0.6748\n",
      "     12            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0088  0.6737\n",
      "     13            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0086  0.6723\n",
      "     14            1.0000        0.0000            1.0000        0.0000  0.0084  0.6736\n",
      "     15            1.0000        0.0000            1.0000        0.0000  0.0081  0.6719\n",
      "     16            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0079  0.6729\n",
      "     17            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0076  0.6744\n",
      "     18            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0073  0.6696\n",
      "     19            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0070  0.6766\n",
      "     20            1.0000        0.0000            1.0000        0.0000  0.0067  0.6717\n",
      "     21            1.0000        0.0000            1.0000        0.0000  0.0064  0.6733\n",
      "     22            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0061  0.6730\n",
      "     23            1.0000        0.0000            1.0000        0.0000  0.0058  0.6729\n",
      "     24            1.0000        0.0000            1.0000        0.0000  0.0055  0.6829\n",
      "     25            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0052  0.6803\n",
      "     26            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0048  0.6812\n",
      "     27            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        \u001b[31m0.0000\u001b[0m  0.0045  0.6843\n",
      "     28            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0042  0.6739\n",
      "     29            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0039  0.6817\n",
      "     30            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0036  0.6777\n",
      "     31            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        0.0000  0.0033  0.6779\n",
      "     32            1.0000        0.0000            1.0000        0.0000  0.0030  0.6772\n",
      "     33            1.0000        0.0000            1.0000        0.0000  0.0027  0.6772\n",
      "     34            1.0000        0.0000            1.0000        0.0000  0.0024  0.6808\n",
      "     35            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        0.0000  0.0021  0.6765\n",
      "     36            1.0000        0.0000            1.0000        0.0000  0.0019  0.6789\n",
      "     37            1.0000        0.0000            1.0000        0.0000  0.0016  0.6816\n",
      "     38            1.0000        0.0000            1.0000        0.0000  0.0014  0.6770\n",
      "     39            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0012  0.6801\n",
      "     40            1.0000        0.0000            1.0000        \u001b[31m0.0000\u001b[0m  0.0010  0.6788\n",
      "     41            1.0000        0.0000            1.0000        0.0000  0.0008  0.6795\n",
      "     42            1.0000        0.0000            1.0000        0.0000  0.0006  0.6790\n",
      "     43            1.0000        \u001b[32m0.0000\u001b[0m            1.0000        0.0000  0.0005  0.6752\n",
      "     44            1.0000        0.0000            1.0000        0.0000  0.0004  0.6785\n",
      "     45            1.0000        0.0000            1.0000        0.0000  0.0003  0.6746\n",
      "     46            1.0000        0.0000            1.0000        0.0000  0.0002  0.6761\n",
      "     47            1.0000        0.0000            1.0000        0.0000  0.0001  0.6789\n",
      "     48            1.0000        0.0000            1.0000        0.0000  0.0000  0.6770\n",
      "     49            1.0000        0.0000            1.0000        0.0000  0.0000  0.6775\n",
      "     50            1.0000        0.0000            1.0000        0.0000  0.0000  0.6790\n"
     ]
    }
   ],
   "source": [
    "fake_clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=predefined_split(fake_testset),\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "fake_clf.fit(fake_trainset, y=None, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 25.73%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(fake_clf.predict(real_evalset) == [y for X,y in real_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {np.mean(fake_clf.predict(fake_evalset) == [y for X,y in fake_evalset])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distância euclidiana entre os dados reais e sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = X_.view(-1, *size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44012.6172)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(real-fake, 2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv_BCI",
   "language": "python",
   "name": "venv_bci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
