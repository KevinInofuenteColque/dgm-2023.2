{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"7d632c8d-789f-47fd-a7cd-cc2db8853459"}},{"cell_type":"code","source":"!pip install braindecode\n!pip install moabb","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:52:54.351615Z","iopub.execute_input":"2023-10-17T22:52:54.351949Z","iopub.status.idle":"2023-10-17T22:53:22.858266Z","shell.execute_reply.started":"2023-10-17T22:52:54.351926Z","shell.execute_reply":"2023-10-17T22:53:22.857381Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting braindecode\n  Downloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from braindecode) (1.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from braindecode) (1.23.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from braindecode) (2.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from braindecode) (1.11.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from braindecode) (3.7.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from braindecode) (3.9.0)\nCollecting skorch (from braindecode)\n  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode) (2.8.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mne->braindecode) (4.66.1)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode) (1.7.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->braindecode) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode) (3.1.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->braindecode) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->braindecode) (2023.3)\nRequirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from skorch->braindecode) (1.2.2)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch->braindecode) (0.9.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->braindecode) (3.10.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->braindecode) (2.31.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->braindecode) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch->braindecode) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch->braindecode) (3.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne->braindecode) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2023.7.22)\nInstalling collected packages: skorch, braindecode\nSuccessfully installed braindecode-0.7 skorch-0.15.0\nCollecting moabb\n  Downloading moabb-0.5.0-py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (6.0)\nCollecting coverage<8.0.0,>=7.0.1 (from moabb)\n  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: h5py<4.0.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (3.9.0)\nRequirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /opt/conda/lib/python3.10/site-packages (from moabb) (3.7.2)\nRequirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (0.61.0)\nRequirement already satisfied: mne<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (1.5.0)\nRequirement already satisfied: numpy<2.0,>=1.22 in /opt/conda/lib/python3.10/site-packages (from moabb) (1.23.5)\nCollecting pandas<2.0.0,>=1.5.2 (from moabb)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (1.7.0)\nCollecting pyriemann<0.4,>=0.3 (from moabb)\n  Downloading pyriemann-0.3.tar.gz (365 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.0/365.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/conda/lib/python3.10/site-packages (from moabb) (2.31.0)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from moabb) (1.2.2)\nRequirement already satisfied: scipy<2.0.0,>=1.9.3 in /opt/conda/lib/python3.10/site-packages (from moabb) (1.11.2)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from moabb) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from moabb) (4.66.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.8.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory-profiler<0.62.0,>=0.61.0->moabb) (5.9.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb) (3.1.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->moabb) (2023.3)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch<2.0.0,>=1.6.0->moabb) (3.10.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyriemann<0.4,>=0.3->moabb) (1.3.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb) (2023.7.22)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.0->moabb) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne<2.0.0,>=1.3.0->moabb) (2.1.3)\nBuilding wheels for collected packages: pyriemann\n  Building wheel for pyriemann (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyriemann: filename=pyriemann-0.3-py2.py3-none-any.whl size=78031 sha256=29d68c0350eccd5890ea9c345da9c55a9c2fc89e3ac94c2e5da6e9b5a6784dbc\n  Stored in directory: /root/.cache/pip/wheels/eb/52/63/ad042f5ca1209b213a326a843e75d730b30bc7a89a79edb187\nSuccessfully built pyriemann\nInstalling collected packages: coverage, pandas, pyriemann, moabb\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.0.2\n    Uninstalling pandas-2.0.2:\n      Successfully uninstalled pandas-2.0.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed coverage-7.3.2 moabb-0.5.0 pandas-1.5.3 pyriemann-0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms, utils\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n\nimport matplotlib.pyplot as plt\n# torch.manual_seed(0) # Set for our testing purposes, please do not change!\n\nfrom braindecode.datasets import MOABBDataset\nfrom braindecode.preprocessing import (\n    exponential_moving_standardize, preprocess, Preprocessor)\nfrom braindecode.preprocessing import \\\n    create_windows_from_events, create_fixed_length_windows\nimport pandas as pd\nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:22.860676Z","iopub.execute_input":"2023-10-17T22:53:22.861125Z","iopub.status.idle":"2023-10-17T22:53:37.589525Z","shell.execute_reply.started":"2023-10-17T22:53:22.861101Z","shell.execute_reply":"2023-10-17T22:53:37.588746Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow not install, you could not use those pipelines\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport numpy as np\n\n\nclass EEG(Dataset):\n\n    def __init__(self, \n                 subject_id = 3, \n                 dataset_name=\"BNCI2014001\", \n                 channels = ['C3', 'Cz', 'C4'],\n                 transform = None):\n        \n        self.raw_dataset     = MOABBDataset(dataset_name = dataset_name, subject_ids=subject_id)\n        self.prepro_dataset  = preprocessor(self.raw_dataset)\n        self.windows_dataset = get_windows(self.prepro_dataset, picks = channels)\n        self.data            = get_tensors_from_windows(self.windows_dataset)\n        self.transform       = transform\n        self.classes         = self.windows_dataset.datasets[0].windows.event_id\n        \n    def __len__(self):\n        return self.data[0].shape[0]\n\n\n    def __getitem__(self,idx):\n\n        # sample = {'signal': torch.from_numpy(self.data[0])[idx], 'label': torch.from_numpy(self.data[1])[idx]}\n\n        sample = (torch.from_numpy(np.expand_dims(self.data[0], axis = 1))[idx], torch.from_numpy(self.data[1])[idx])\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\n\ndef get_noise(n_samples, input_dim, device='cpu'):\n    '''\n    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)\n    creates a tensor of that shape filled with random numbers from the normal distribution.\n    Parameters:\n        n_samples: the number of samples to generate, a scalar\n        input_dim: the dimension of the input vector, a scalar\n        device: the device type\n    '''\n    return torch.randn(n_samples, input_dim, device=device)\n\n\ndef get_one_hot_labels(labels, n_classes):\n    '''\n    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\n    Parameters:\n        labels: tensor of labels from the dataloader, size (?)\n        n_classes: the total number of classes in the dataset, an integer scalar\n    '''\n    return F.one_hot(labels,n_classes)\n\ndef combine_vectors(x, y):\n    '''\n    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\n    Parameters:\n      x: (n_samples, ?) the first vector. \n        In this assignment, this will be the noise vector of shape (n_samples, z_dim), \n        but you shouldn't need to know the second dimension's size.\n      y: (n_samples, ?) the second vector.\n        Once again, in this assignment this will be the one-hot class vector \n        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.\n    '''\n    combined = torch.cat((x.float(),y.float()), 1)\n    return combined\n\ndef get_input_dimensions(z_dim, eeg_shape, n_classes):\n    '''\n    Function for getting the size of the conditional input dimensions \n    from z_dim, the image shape, and number of classes.\n    Parameters:\n        z_dim: the dimension of the noise vector, a scalar\n        eeg_shape: the shape of each EEG data as (C, W, H), which is (1, 3, 400), that is, we choose 3 channels (3 electrodes)\n        n_classes: the total number of classes in the dataset, an integer scalar\n                (4 for EEG, that is 4 movements - tongue, left hand, right hand and feet)\n    Returns: \n        generator_input_dim: the input dimensionality of the conditional generator, \n                          which takes the noise and class vectors\n        discriminator_im_chan: the number of input channels to the discriminator\n                            (e.g. C x 3 x 400 for EEG)\n    '''\n    generator_input_dim = z_dim + n_classes\n    discriminator_im_chan = eeg_shape[0] + n_classes\n    return generator_input_dim, discriminator_im_chan\n\ndef weights_init(m):\n    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, torch.nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)\n\n\n# preprocess function\ndef preprocessor(\n    dataset,\n    low_cut_hz = 4.,   # low cut frequency for filtering\n    high_cut_hz = 38., # high cut frequency for filtering\n    newfreq = 100, # Paramater for resampling\n    factor = 1e6, # Parameter for scaling\n    ):\n\n    preprocessors = [\n        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n        Preprocessor(lambda data: np.multiply(data, factor)),  # Convert from V to uV\n        Preprocessor(\"resample\", sfreq=newfreq), # Resampling\n        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\") # Common Average Reference\n    ]\n    \n    # Transform the data\n    # return preprocess(dataset, preprocessors, n_jobs = -1)\n    return preprocess(dataset, preprocessors)\n\n\n\n# Get Windows from Dataset\n\ndef get_windows(\n        dataset, \n        trial_start_offset_samples=0,\n        trial_stop_offset_samples=100,\n        window_size_samples=400,\n        window_stride_samples=100,\n        preload=True,\n        # mapping = {'left_hand': 0, 'right_hand': 1},\n        picks = ['C3', 'Cz', 'C4']\n        ):\n    \n    windows_dataset = create_windows_from_events(\n        dataset,\n        trial_start_offset_samples = trial_start_offset_samples,\n        trial_stop_offset_samples  = trial_stop_offset_samples,\n        window_size_samples        = window_size_samples,\n        window_stride_samples      = window_stride_samples,\n        preload                    = True,\n        # mapping = {'left_hand': 0, 'right_hand': 1},\n        picks                      = picks\n        )\n    \n    return windows_dataset\n\n\ndef get_tensors_from_windows(windows_dataset):\n    windows_list = []\n    labels_list = []\n    n_runs = len(windows_dataset.datasets)\n    for i in range(n_runs):\n        windows_list.append(windows_dataset.datasets[i].windows.get_data())\n        labels_list.append(windows_dataset.datasets[i].y)\n        \n    stacked_tensor = np.concatenate(windows_list, axis=0)\n    stacked_labels = np.concatenate(labels_list, axis=0)\n        \n    return stacked_tensor, stacked_labels\n\n\n\n\n\n##### GENERATOR #####\nclass Generator(nn.Module):\n    '''\n    Generator Class\n    Values:\n        input_dim: the dimension of the input vector, a scalar\n        im_chan: the number of channels of the output eeg, a scalar\n        hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, input_dim=68, im_chan=1, hidden_dim=64):\n        super(Generator, self).__init__()\n        self.input_dim = input_dim\n        # Build the neural network\n        self.gen = nn.Sequential(\n            self.make_gen_block(input_dim, hidden_dim * 4,      kernel_size = (1,60), stride = (1,1)),\n            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size = (1,60), stride = (1,1)),\n            self.make_gen_block(hidden_dim * 2, hidden_dim,     kernel_size = (1,60), stride = (1,1)),\n            self.make_gen_block(hidden_dim, im_chan,            kernel_size = (3,50), stride = (1,2), padding = (0,2), final_layer=True),\n        )\n\n    def make_gen_block(self, input_channels, output_channels, kernel_size, stride, padding = 0, final_layer=False):\n        '''\n        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n        Parameters:\n            input_channels: how many channels the input feature representation has\n            output_channels: how many channels the output feature representation should have\n            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n            stride: the stride of the convolution\n            final_layer: a boolean, true if it is the final layer and false otherwise \n                      (affects activation and batchnorm)\n        '''\n        if not final_layer:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n                nn.BatchNorm2d(output_channels),\n                nn.ReLU(inplace=True),\n            )\n        else:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n                nn.Tanh(),\n            )\n\n    def forward(self, noise):\n        '''\n        Function for completing a forward pass of the generator: Given a noise tensor, \n        returns generated images.\n        Parameters:\n            noise: a noise tensor with dimensions (n_samples, input_dim)\n        '''\n        x = noise.view(len(noise), self.input_dim, 1, 1)\n        return self.gen(x)\n\n\n##### Discriminator #####\nclass Discriminator(nn.Module):\n    '''\n    Discriminator Class\n    Values:\n      im_chan: the number of channels of the output eeg, a scalar\n      hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, im_chan=5, hidden_dim=64):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            self.make_disc_block(im_chan, hidden_dim,        kernel_size = (1,50), stride = (2,4)),\n            self.make_disc_block(hidden_dim, hidden_dim * 2, kernel_size = (1,50), stride = (2,4)),\n            self.make_disc_block(hidden_dim * 2, 1,          kernel_size = (1,10), stride = (2,1), final_layer=True),\n        )\n\n    def make_disc_block(self, input_channels, output_channels, kernel_size, stride, final_layer=False):\n        '''\n        Function to return a sequence of operations corresponding to a discriminator block of the DCGAN; \n        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).\n        Parameters:\n            input_channels: how many channels the input feature representation has\n            output_channels: how many channels the output feature representation should have\n            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n            stride: the stride of the convolution\n            final_layer: a boolean, true if it is the final layer and false otherwise \n                      (affects activation and batchnorm)\n        '''\n        if not final_layer:\n            return nn.Sequential(\n                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.LeakyReLU(0.2, inplace=True),\n            )\n        else:\n            return nn.Sequential(\n                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n            )\n\n    def forward(self, image):\n        '''\n        Function for completing a forward pass of the discriminator: Given an image tensor, \n        returns a 1-dimension tensor representing fake/real.\n        Parameters:\n            image: a flattened image tensor with dimension (im_chan)\n        '''\n        disc_pred = self.disc(image)\n        return disc_pred.view(len(disc_pred), -1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:37.590539Z","iopub.execute_input":"2023-10-17T22:53:37.591016Z","iopub.status.idle":"2023-10-17T22:53:37.613396Z","shell.execute_reply.started":"2023-10-17T22:53:37.590991Z","shell.execute_reply":"2023-10-17T22:53:37.612791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# from eeg import EEG\n# from MyGAN import *\n# from gan_input_functions import *\n# from helper_functions import *\n\n\nimport torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms, utils\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom sklearn.model_selection import train_test_split\n\n\nimport matplotlib.pyplot as plt\n# torch.manual_seed(0) # Set for our testing purposes, please do not change!\n\nimport pandas as pd\nimport numpy as np","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":241,"status":"error","timestamp":1697481957249,"user":{"displayName":"Larissa Rangel de Azevedo","userId":"11239044081097926538"},"user_tz":180},"id":"e63aaedc-83f1-4843-a47b-7fd402a4b31d","outputId":"b4b20d6d-7563-4bf1-c690-c7c583ae077c","execution":{"iopub.status.busy":"2023-10-17T22:53:37.614873Z","iopub.execute_input":"2023-10-17T22:53:37.615435Z","iopub.status.idle":"2023-10-17T22:53:37.631461Z","shell.execute_reply.started":"2023-10-17T22:53:37.615401Z","shell.execute_reply":"2023-10-17T22:53:37.630762Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Getting data","metadata":{"id":"d7a2af7d-c1d1-45d4-8958-81d053d7031a"}},{"cell_type":"code","source":"eeg_data = EEG(subject_id=[1])","metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1697481806436,"user":{"displayName":"Larissa Rangel de Azevedo","userId":"11239044081097926538"},"user_tz":180},"id":"207d1fc1-361f-465d-a56d-7cf94ad860b9","scrolled":true,"execution":{"iopub.status.busy":"2023-10-17T22:53:37.632252Z","iopub.execute_input":"2023-10-17T22:53:37.632445Z","iopub.status.idle":"2023-10-17T22:53:50.435677Z","shell.execute_reply.started":"2023-10-17T22:53:37.632428Z","shell.execute_reply":"2023-10-17T22:53:50.434980Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/moabb/datasets/download.py:54: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n  set_config(key, get_config(\"MNE_DATA\"))\nDownloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A01T.mat'.\n","output_type":"stream"},{"name":"stdout","text":"MNE_DATA is not already configured. It will be set to default location in the home directory - /root/mne_data\nAll datasets will be downloaded to this location, if anything is already downloaded, please move manually to this location\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 49.7GB/s]\nSHA256 hash of downloaded file: 054f02e70cf9c4ada1517e9b9864f45407939c1062c6793516585c6f511d0325\nUse this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\nDownloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A01E.mat'.\n100%|█████████████████████████████████████| 43.8M/43.8M [00:00<00:00, 49.8GB/s]\nSHA256 hash of downloaded file: 53d415f39c3d7b0c88b894d7b08d99bcdfe855ede63831d3691af1a45607fb62\nUse this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n","output_type":"stream"},{"name":"stdout","text":"48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\n48 events found\nEvent IDs: [1 2 3 4]\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n  warn('Preprocessing choices with lambda functions cannot be saved.')\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\nFiltering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nNOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Filtering raw data in 1 contiguous segment\nSetting up band-pass filter from 4 - 38 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 4.00\n- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n- Upper passband edge: 38.00 Hz\n- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n- Filter length: 165 samples (1.650 s)\n\nApplying average reference.\nApplying a custom ('EEG',) reference.\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\nUsed Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Configuration","metadata":{"id":"17d344cd-6063-4a15-beef-4fc2c618deb9"}},{"cell_type":"code","source":"# n_epochs = 500\nz_dim = 64\n# display_step = 500\n# lr = 0.00001\nn_classes = 4\n# batch_size = 32\ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:50.436734Z","iopub.execute_input":"2023-10-17T22:53:50.436946Z","iopub.status.idle":"2023-10-17T22:53:50.440548Z","shell.execute_reply.started":"2023-10-17T22:53:50.436926Z","shell.execute_reply":"2023-10-17T22:53:50.439702Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# PATH = \"../Weights/Conv_Cond_Gan_v2/Gen_Weights_v2.pt\"","metadata":{"id":"cc7cafd0-c3aa-4aeb-b42e-450fe449d7e0","execution":{"iopub.status.busy":"2023-10-17T22:53:50.441660Z","iopub.execute_input":"2023-10-17T22:53:50.441879Z","iopub.status.idle":"2023-10-17T22:53:50.592940Z","shell.execute_reply.started":"2023-10-17T22:53:50.441861Z","shell.execute_reply":"2023-10-17T22:53:50.592249Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"gen = Generator()","metadata":{"id":"29cfaf43-b0d8-418f-81ae-2f873cf9a3f2","execution":{"iopub.status.busy":"2023-10-17T23:07:12.982968Z","iopub.execute_input":"2023-10-17T23:07:12.983585Z","iopub.status.idle":"2023-10-17T23:07:13.019963Z","shell.execute_reply.started":"2023-10-17T23:07:12.983556Z","shell.execute_reply":"2023-10-17T23:07:13.019243Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"%mkdir weights\n%cd weights","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:08:35.924677Z","iopub.execute_input":"2023-10-17T23:08:35.925293Z","iopub.status.idle":"2023-10-17T23:08:36.957531Z","shell.execute_reply.started":"2023-10-17T23:08:35.925264Z","shell.execute_reply":"2023-10-17T23:08:36.956441Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# !gdown https://drive.google.com/uc?1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55\n!gdown \"https://drive.google.com/file/d/1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55/view?usp=share_link\" -O weights.pt","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:16:08.820980Z","iopub.execute_input":"2023-10-17T23:16:08.821570Z","iopub.status.idle":"2023-10-17T23:16:10.489132Z","shell.execute_reply.started":"2023-10-17T23:16:08.821540Z","shell.execute_reply":"2023-10-17T23:16:10.488194Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/parse_url.py:44: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/file/d/1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55/view?usp=share_link\nTo: /root/weights/weights.pt\n83.7kB [00:00, 329MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:16:11.792466Z","iopub.execute_input":"2023-10-17T23:16:11.793133Z","iopub.status.idle":"2023-10-17T23:16:12.817009Z","shell.execute_reply.started":"2023-10-17T23:16:11.793103Z","shell.execute_reply":"2023-10-17T23:16:12.815827Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":" 1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55\t    'view?usp=share_link'\n index.html\t\t\t\t    'view?usp=share_link.1'\n'uc?1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55'\t     weights.pt\n'uc?id[1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55]'\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:15:51.048882Z","iopub.execute_input":"2023-10-17T23:15:51.049181Z","iopub.status.idle":"2023-10-17T23:15:52.077928Z","shell.execute_reply.started":"2023-10-17T23:15:51.049156Z","shell.execute_reply":"2023-10-17T23:15:52.076858Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"/root/weights\n","output_type":"stream"}]},{"cell_type":"code","source":"gen.load_state_dict(torch.load(\"./weights.pt\"))","metadata":{"id":"6e6d5f2a-ce07-4c75-9359-3454d61591a4","outputId":"a7506789-6d84-4d71-e260-d1d252c84100","execution":{"iopub.status.busy":"2023-10-17T23:16:14.807953Z","iopub.execute_input":"2023-10-17T23:16:14.808582Z","iopub.status.idle":"2023-10-17T23:16:14.893285Z","shell.execute_reply.started":"2023-10-17T23:16:14.808549Z","shell.execute_reply":"2023-10-17T23:16:14.892296Z"},"trusted":true},"execution_count":78,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./weights.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1033\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1033\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '<'."],"ename":"UnpicklingError","evalue":"invalid load key, '<'.","output_type":"error"}]},{"cell_type":"markdown","source":"## Generate Samples","metadata":{"id":"0f02a035-99d4-411b-afce-b78333afd6e3"}},{"cell_type":"code","source":"\n\n\ndef generate_samples_with_labels(label, n_samples, generator, z_dim = 64, channel = None, extra_dim = True):\n    '''\n    Function for generating samples, once the generator has been trained\n        label: label of the movement to be sampled. See dictionary below\n        {'feet': 0, 'left_hand': 1, 'right_hand': 2, 'tongue': 3}\n        n_samples: number of samples to be generated\n        channel: electrode {'C3': 0, 'Cz': 1, 'C4': 2} -> Default: All channels\n        generator: the trained generator\n    '''\n\n    n_classes = 4\n\n    if channel == None:\n        noise_4_gen = get_noise(n_samples, z_dim)\n        label = get_one_hot_labels(torch.Tensor([label]).long(), n_classes).repeat(n_samples,1)\n\n        noise_and_labels = combine_vectors(noise_4_gen, label)\n        fake = generator(noise_and_labels)\n\n        if extra_dim == False:\n            fake = fake.reshape((fake.shape[0], fake.shape[2], fake.shape[3]))\n        return fake\n    else:\n        noise_4_gen = get_noise(n_samples, z_dim)\n        label = get_one_hot_labels(torch.Tensor([label]).long(), n_classes).repeat(n_samples,1)\n\n        noise_and_labels = combine_vectors(noise_4_gen, label)\n        fake = generator(noise_and_labels)\n        filtered_channel_fake = torch.select(fake, dim = 2, index = channel)\n\n        if extra_dim == False:\n            filtered_channel_fake = filtered_channel_fake.reshape((filtered_channel_fake.shape[0], filtered_channel_fake.shape[2]))\n\n        return filtered_channel_fake\n\n","metadata":{"id":"4e774492-34e5-4bdd-87fb-4fffb7b03f53","execution":{"iopub.status.busy":"2023-10-17T22:53:50.619433Z","iopub.execute_input":"2023-10-17T22:53:50.619631Z","iopub.status.idle":"2023-10-17T22:53:50.627258Z","shell.execute_reply.started":"2023-10-17T22:53:50.619614Z","shell.execute_reply":"2023-10-17T22:53:50.626629Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Filter Label and channels of real data","metadata":{"id":"80ebc0c8-e621-4096-8982-3a4bd35d63b3"}},{"cell_type":"code","source":"def filter_label_and_channel(eeg_data, label, channel):\n    '''\n    Function to filter label and channel of original eeg data.\n        eeg_data: raw eeg data\n        label: class of movement\n        channel: electrode --   {'C3': 0, 'Cz': 1, 'C4': 2}\n    '''\n\n\n    mask = torch.where(eeg_data[:][1] == label, 1, 0)\n    filtered_eeg = eeg_data[:][0][torch.nonzero(mask).flatten()]\n    filtered_eeg = filtered_eeg.reshape((filtered_eeg.shape[0], filtered_eeg.shape[2], filtered_eeg.shape[3] ))\n    filtered_channel_eeg = torch.select(filtered_eeg, dim = 1, index = channel)\n\n    return filtered_channel_eeg","metadata":{"id":"c3069eb5-02ae-4109-92f2-7ccd982b3acb","execution":{"iopub.status.busy":"2023-10-17T22:53:50.629556Z","iopub.execute_input":"2023-10-17T22:53:50.629795Z","iopub.status.idle":"2023-10-17T22:53:50.643675Z","shell.execute_reply.started":"2023-10-17T22:53:50.629775Z","shell.execute_reply":"2023-10-17T22:53:50.642991Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Classification Helper Functions","metadata":{"id":"b434da40-da1d-4b5e-a9b5-79e195c77c3b"}},{"cell_type":"code","source":"def generate_samples_for_classification(n_samples, generator, z_dim = 64):\n    '''\n    Function for generating equal label samples for the classifier.\n        n_samples: number of samples to be generated\n        generator: the trained generator\n    '''\n    n_classes = 4\n\n    n_samples_partial = int(n_samples/n_classes)\n    noise_4_gen = get_noise(n_samples, z_dim)\n\n    label = [0,1,2,3]\n\n    label = [get_one_hot_labels(torch.Tensor([i]).long(), n_classes).repeat(n_samples_partial,1) for i in label]\n\n    label_concat = torch.zeros_like(torch.Tensor(0,4))\n    for i in range(len(label)):\n        label_concat = torch.cat((label_concat,label[i]), 0)\n\n    noise_and_labels = combine_vectors(noise_4_gen, label_concat)\n\n    fake = generator(noise_and_labels)\n\n    original_labels = torch.argmax(label_concat,dim = 1)\n    return (fake,original_labels)\n","metadata":{"id":"2d1eafe6-d073-4a4e-a92f-93aa26690224","execution":{"iopub.status.busy":"2023-10-17T22:53:50.644671Z","iopub.execute_input":"2023-10-17T22:53:50.644910Z","iopub.status.idle":"2023-10-17T22:53:50.659697Z","shell.execute_reply.started":"2023-10-17T22:53:50.644891Z","shell.execute_reply":"2023-10-17T22:53:50.658932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def add_real_fake(real_eeg, fake_eeg):\n\n    real_data = real_eeg[:]\n    fake_data = fake_eeg\n\n    complete_eeg_data = torch.cat((real_data[0], fake_data[0]), dim = 0)\n    complete_label_data = torch.cat((real_data[1], fake_data[1]), dim = 0)\n\n    return (complete_eeg_data, complete_label_data)\n","metadata":{"id":"03b16c92-9229-4866-942a-00cf2cc586d1","outputId":"3724cb4d-7149-4ac4-b036-6df8626bc494","execution":{"iopub.status.busy":"2023-10-17T22:53:50.660505Z","iopub.execute_input":"2023-10-17T22:53:50.660797Z","iopub.status.idle":"2023-10-17T22:53:50.671988Z","shell.execute_reply.started":"2023-10-17T22:53:50.660777Z","shell.execute_reply":"2023-10-17T22:53:50.671231Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Classifier","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.T = 400\n\n        # Layer 1\n        self.conv1 = nn.Conv2d(1, 16, (1, 400), padding = 0)\n        self.batchnorm1 = nn.BatchNorm2d(16, False)\n        self.tconv2d1 = nn.ConvTranspose2d(16, 16, kernel_size = (118,1), stride = (1,1))\n        \n        # Layer 2\n        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n        self.conv2 = nn.Conv2d(1, 4, (2, 2))\n        self.batchnorm2 = nn.BatchNorm2d(4, False)\n        self.pooling2 = nn.MaxPool2d(2, 1)\n\n        # # Layer 3\n        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n        self.batchnorm3 = nn.BatchNorm2d(4, False)\n        self.pooling3 = nn.MaxPool2d(2, 1)\n\n        # # # FC Layer\n        # # # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n        # # # I have 120 timepoints.\n        self.fc1 = nn.Linear(4*14*33, 4)\n\n\n    def forward(self, x):\n\n        # Layer 1\n        x = F.elu(self.conv1(x))\n        x = self.batchnorm1(x)\n        x = F.dropout(x, 0.25)\n        x = x.permute(0, 3, 1, 2)\n\n        # Layer 2\n        x = self.padding1(x)\n        x = self.conv2(x)\n        x = F.elu(x)\n        x = self.batchnorm2(x)\n        x = F.dropout(x, 0.25)\n        x = self.pooling2(x)\n\n        # Layer 3\n        x = self.padding2(x)\n        x = F.elu(self.conv3(x))\n        x = self.batchnorm3(x)\n        x = F.dropout(x, 0.25)\n        x = self.pooling3(x)\n\n        # FC Layer\n        x = x.reshape(-1, 4*14*33)\n        x = F.softmax(self.fc1(x), dim = 1)\n        \n        return x\n\nclass LinClassifier(nn.Module):\n    def __init__(self,D_in,H,D_out):\n        super(LinClassifier,self).__init__()\n        self.linear1=nn.Linear(D_in,H)\n        self.linear2=nn.Linear(H,D_out)\n\n        \n    def forward(self,x):\n        x=torch.sigmoid(self.linear1(x))  \n        x=self.linear2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:50.672879Z","iopub.execute_input":"2023-10-17T22:53:50.673158Z","iopub.status.idle":"2023-10-17T22:53:50.684234Z","shell.execute_reply.started":"2023-10-17T22:53:50.673139Z","shell.execute_reply":"2023-10-17T22:53:50.683444Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"## data\nX = eeg_data[:][0].numpy()\n# X = torch.select(eeg_data[:][0], 2, 0).numpy()\nY = F.one_hot(eeg_data[:][1], n_classes).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:50.684942Z","iopub.execute_input":"2023-10-17T22:53:50.685237Z","iopub.status.idle":"2023-10-17T22:53:50.762241Z","shell.execute_reply.started":"2023-10-17T22:53:50.685209Z","shell.execute_reply":"2023-10-17T22:53:50.761699Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Get weights from internet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://drive.google.com/file/d/1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55/view?usp=share_link","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:06:46.532552Z","iopub.execute_input":"2023-10-17T23:06:46.533215Z","iopub.status.idle":"2023-10-17T23:06:48.082857Z","shell.execute_reply.started":"2023-10-17T23:06:46.533183Z","shell.execute_reply":"2023-10-17T23:06:48.081926Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"--2023-10-17 23:06:47--  https://drive.google.com/file/d/1YX5kKm1ryJxh6ZAOEttlnr__RAfeni55/view?usp=share_link\nResolving drive.google.com (drive.google.com)... 74.125.201.139, 74.125.201.102, 74.125.201.101, ...\nConnecting to drive.google.com (drive.google.com)|74.125.201.139|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘view?usp=share_link’\n\nview?usp=share_link     [ <=>                ]  81.75K  --.-KB/s    in 0.002s  \n\n2023-10-17 23:06:47 (39.4 MB/s) - ‘view?usp=share_link’ saved [83714]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-10-17T23:06:50.886111Z","iopub.execute_input":"2023-10-17T23:06:50.886785Z","iopub.status.idle":"2023-10-17T23:06:51.922206Z","shell.execute_reply.started":"2023-10-17T23:06:50.886752Z","shell.execute_reply":"2023-10-17T23:06:51.921149Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"'view?usp=share_link'\n","output_type":"stream"}]},{"cell_type":"code","source":"# Complete REAL+FAKE\n# fake_data = generate_samples_for_classification(X.shape[0], gen)\n# complete_dataset = add_real_fake(eeg_data,fake_data)\n# X = complete_dataset[:][0].detach().numpy()\n# # X = torch.select(eeg_data[:][0], 2, 0).numpy()\n# Y = F.one_hot(complete_dataset[:][1], n_classes).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:50.764282Z","iopub.execute_input":"2023-10-17T22:53:50.764478Z","iopub.status.idle":"2023-10-17T22:53:50.768195Z","shell.execute_reply.started":"2023-10-17T22:53:50.764461Z","shell.execute_reply":"2023-10-17T22:53:50.767533Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"### Train test split\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3, random_state=42)\nx_train = x_train.astype(\"float32\")\nx_val = x_val.astype(\"float32\")\n\ny_train = y_train.astype(\"float32\")\ny_val = y_val.astype(\"float32\")\n\n\n## transforming tensors\nx_val = torch.from_numpy(x_val).cuda()\ny_val = torch.from_numpy(y_val).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:50.769150Z","iopub.execute_input":"2023-10-17T22:53:50.769392Z","iopub.status.idle":"2023-10-17T22:53:56.640761Z","shell.execute_reply.started":"2023-10-17T22:53:50.769363Z","shell.execute_reply":"2023-10-17T22:53:56.640035Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# DataLoader\nclass Data(Dataset):\n    def __init__(self):\n        self.x=torch.from_numpy(x_train).cuda(0)\n        self.y=torch.from_numpy(y_train).cuda(0)\n        self.len=self.x.shape[0]\n    def __getitem__(self,index):      \n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:56.641590Z","iopub.execute_input":"2023-10-17T22:53:56.641853Z","iopub.status.idle":"2023-10-17T22:53:56.646192Z","shell.execute_reply.started":"2023-10-17T22:53:56.641831Z","shell.execute_reply":"2023-10-17T22:53:56.645671Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"n_epochs = 10\nlr = 0.00001\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:56.647248Z","iopub.execute_input":"2023-10-17T22:53:56.647804Z","iopub.status.idle":"2023-10-17T22:53:56.697643Z","shell.execute_reply.started":"2023-10-17T22:53:56.647774Z","shell.execute_reply":"2023-10-17T22:53:56.696906Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data_set=Data()\ntrainloader = DataLoader(dataset=data_set,batch_size=batch_size)\ndata_set.x.shape, data_set.y.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:56.699606Z","iopub.execute_input":"2023-10-17T22:53:56.699914Z","iopub.status.idle":"2023-10-17T22:53:56.713382Z","shell.execute_reply.started":"2023-10-17T22:53:56.699892Z","shell.execute_reply":"2023-10-17T22:53:56.712710Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(torch.Size([806, 1, 3, 400]), torch.Size([806, 4]))"},"metadata":{}}]},{"cell_type":"code","source":"classif = Classifier().cuda(0)\n# criterion = F.cross_entropy()\ncriterion = nn.BCELoss()\n# criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(classif.parameters(), lr = lr)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:56.714339Z","iopub.execute_input":"2023-10-17T22:53:56.714596Z","iopub.status.idle":"2023-10-17T22:53:56.737092Z","shell.execute_reply.started":"2023-10-17T22:53:56.714576Z","shell.execute_reply":"2023-10-17T22:53:56.736510Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# loss_list      = []\n# acc_train_list = []\n# acc_val_list   = []\n\n# step = 0\n# progress_show = 20\n\n# #n_epochs\n# for epoch in range(n_epochs):\n    \n#     for x, y in trainloader:\n        \n#         # Send variables to GPU\n#         x, y = x.cuda(0), y.cuda(0)\n        \n#         #clear gradient \n#         optimizer.zero_grad()\n#         #make a prediction \n#         z=classif(x)\n#         # calculate loss, da Cross Entropy\n#         loss=criterion(z,y)\n#         # # calculate gradients of parameters \n#         loss.backward()\n#         # # update parameters \n#         optimizer.step()\n        \n#         loss_list.append(round(loss.data.item(), 3))\n\n#     # Train Evaluation\n#     acc_train = ((torch.argmax(z, 1) == torch.argmax(y, 1)).float().mean()).item()\n#     acc_train = round(acc_train, 3)\n#     acc_train_list.append(acc_train)\n\n#     # Validation Evaluation\n#     z_val = classif(x_val)\n#     acc_val = ((torch.argmax(z_val, 1) == torch.argmax(y_val, 1)).float().mean()).item()\n#     acc_val = round(acc_val, 3)\n#     acc_val_list.append(acc_val)\n\n#     # if acc_val > best_acc_val:\n#         # torch.save(classif, 'best-model.pt') \n#         # print(acc_val)\n\n        \n#     best_acc_val = max([i for i in acc_val_list])\n    \n#     # if step % progress_show == 0:\n#     #     print('epoch {}, loss {}, acc_train {}, acc_val {}'.format(epoch, loss.item(), acc_train,  acc_val))\n\n\n#     step += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:53:56.737970Z","iopub.execute_input":"2023-10-17T22:53:56.738174Z","iopub.status.idle":"2023-10-17T22:53:56.741734Z","shell.execute_reply.started":"2023-10-17T22:53:56.738156Z","shell.execute_reply":"2023-10-17T22:53:56.741097Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Test parameters","metadata":{}},{"cell_type":"code","source":"def train(lr, batch_size):\n\n    n_epochs = 500\n\n    data_set=Data()\n    trainloader = DataLoader(dataset=data_set,batch_size=batch_size)\n\n    classif = Classifier().cuda(0)\n    # criterion = F.cross_entropy()\n    criterion = nn.BCELoss()\n    # criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(classif.parameters(), lr = lr)\n    \n    loss_list      = []\n    acc_train_list = []\n    acc_val_list   = []\n    \n#     step = 0\n#     progress_show = 20\n    \n    #n_epochs\n    for epoch in range(n_epochs):\n        for x, y in (trainloader):\n            \n            # Send variables to GPU\n            x, y = x.cuda(0), y.cuda(0)\n            \n            #clear gradient \n            optimizer.zero_grad()\n            #make a prediction \n            z=classif(x)\n            # calculate loss, da Cross Entropy\n            loss=criterion(z,y)\n            # # calculate gradients of parameters \n            loss.backward()\n            # # update parameters \n            optimizer.step()\n            \n            loss_list.append(round(loss.data.item(), 3))\n    \n        # Train Evaluation\n        acc_train = ((torch.argmax(z, 1) == torch.argmax(y, 1)).float().mean()).item()\n        acc_train = round(acc_train, 3)\n        acc_train_list.append(acc_train)\n    \n        # Validation Evaluation\n        z_val = classif(x_val)\n        acc_val = ((torch.argmax(z_val, 1) == torch.argmax(y_val, 1)).float().mean()).item()\n        acc_val = round(acc_val, 3)\n        acc_val_list.append(acc_val)\n        best_acc_val = max([i for i in acc_val_list])\n\n#         if step % progress_show == 0:\n#             print(f\"Epoch {epoch}\")\n        \n        # if acc_val > best_acc_val:\n            # torch.save(classif, 'best-model.pt') \n            # print(acc_val)\n#         step += 1\n        \n    print(\"Learning rate:\",lr,\"batch_size:\", batch_size, \"Accuracy\", best_acc_val)\n    # return best_acc_val\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:58:40.922558Z","iopub.execute_input":"2023-10-17T22:58:40.923150Z","iopub.status.idle":"2023-10-17T22:58:40.931010Z","shell.execute_reply.started":"2023-10-17T22:58:40.923120Z","shell.execute_reply":"2023-10-17T22:58:40.930350Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"lr_list = [0.00001, 0.0001, 0.001]\nbatch_size = [16, 64, 256]\n\nfor lr in lr_list:\n    for bs in batch_size:\n        \n        train(lr = lr, batch_size = bs)","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:58:45.137510Z","iopub.execute_input":"2023-10-17T22:58:45.138082Z","iopub.status.idle":"2023-10-17T23:04:48.598523Z","shell.execute_reply.started":"2023-10-17T22:58:45.138051Z","shell.execute_reply":"2023-10-17T23:04:48.597794Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Learning rate: 1e-05 batch_size: 16 Accuracy 0.448\nLearning rate: 1e-05 batch_size: 64 Accuracy 0.448\nLearning rate: 1e-05 batch_size: 256 Accuracy 0.402\nLearning rate: 0.0001 batch_size: 16 Accuracy 0.483\nLearning rate: 0.0001 batch_size: 64 Accuracy 0.454\nLearning rate: 0.0001 batch_size: 256 Accuracy 0.48\nLearning rate: 0.001 batch_size: 16 Accuracy 0.471\nLearning rate: 0.001 batch_size: 64 Accuracy 0.46\nLearning rate: 0.001 batch_size: 256 Accuracy 0.451\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:54:25.692660Z","iopub.execute_input":"2023-10-17T22:54:25.693347Z","iopub.status.idle":"2023-10-17T22:54:26.636258Z","shell.execute_reply.started":"2023-10-17T22:54:25.693315Z","shell.execute_reply":"2023-10-17T22:54:26.635599Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 0\nLearning rate: 1e-05 batch_size: 32 Accuracy 0.28\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classif = Classifier().cuda(0)\n# classif.load_state_dict(torch.load(\"./best-model.pt\"))\n\n# z_val = classif(x_val)\n# acc_val = ((torch.argmax(z_val, 1) == torch.argmax(y_val, 1)).float().mean()).item()\n# acc_val","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:54:05.684961Z","iopub.status.idle":"2023-10-17T22:54:05.685429Z","shell.execute_reply.started":"2023-10-17T22:54:05.685176Z","shell.execute_reply":"2023-10-17T22:54:05.685200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# z_val = classif(x_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:54:05.688641Z","iopub.status.idle":"2023-10-17T22:54:05.689409Z","shell.execute_reply.started":"2023-10-17T22:54:05.689255Z","shell.execute_reply":"2023-10-17T22:54:05.689272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def evaluate(model, X, Y, params = [\"acc\"]):\n#     results = []\n#     batch_size = 100\n\n#     predicted = []\n\n#     X = X.cpu().numpy()\n#     Y = Y.cpu()\n#     # X = X\n\n#     for i in range(int(len(X)/batch_size)):\n#         s = i*batch_size\n#         e = i*batch_size+batch_size\n\n#         inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n#         pred = model(inputs)\n\n#         predicted.append(pred.data.cpu().numpy())\n\n\n#     inputs = Variable(torch.from_numpy(X).cuda(0))\n#     predicted = model(inputs)\n\n#     predicted = predicted.data.cpu().numpy()\n\n#     for param in params:\n#         if param == 'acc':\n#             results.append(accuracy_score(Y, np.round(predicted)))\n#         if param == \"auc\":\n#             results.append(roc_auc_score(Y, predicted))\n#         if param == \"recall\":\n#             results.append(recall_score(Y, np.round(predicted)))\n#         if param == \"precision\":\n#             results.append(precision_score(Y, np.round(predicted)))\n#         if param == \"fmeasure\":\n#             precision = precision_score(Y, np.round(predicted))\n#             recall = recall_score(Y, np.round(predicted))\n#             results.append(2*precision*recall/ (precision+recall))\n#     return results","metadata":{"id":"fYXOTGHks4Z-","execution":{"iopub.status.busy":"2023-10-17T22:54:05.690353Z","iopub.status.idle":"2023-10-17T22:54:05.690869Z","shell.execute_reply.started":"2023-10-17T22:54:05.690688Z","shell.execute_reply":"2023-10-17T22:54:05.690704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 64\n# epochs = 5\n# for epoch in range(epochs):  # loop over the dataset multiple times\n#     # print (\"\\nEpoch \", epoch)\n\n#     running_loss = 0.0\n#     for i in range(int(len(X_train_eeg)/batch_size-1)):\n#         s = i*batch_size\n#         e = i*batch_size+batch_size\n        \n#         inputs = torch.from_numpy(X_train_eeg[s:e].numpy())\n#         labels = torch.FloatTensor(np.array([y_train_eeg[s:e].numpy()]).T*1.0)\n        # labels = torch.Tensor(labels.flatten())\n        \n    #     # # wrap them in Variable\n    #     inputs, labels = Variable(inputs.cuda(0), requires_grad=True), Variable(labels.cuda(0), requires_grad=True)\n\n    #     # # zero the parameter gradients\n    #     optimizer.zero_grad()\n        \n    #     outputs = classif(inputs)\n    #     outputs = torch.argmax(outputs, dim = 1).to(torch.float32)\n    #     outputs = outputs.reshape((-1,1))\n        \n    #     # loss = criterion(outputs, labels)\n    #     loss = F.cross_entropy(outputs, labels)\n    #     loss.backward()\n    #     optimizer.step()\n    #     running_loss += loss.item()\n\n    # # Validation accuracy\n    # params = [\"acc\", \"auc\", \"fmeasure\"]\n    # print (params)\n    # print (\"Training Loss \", running_loss)\n    # print (\"Train - \", evaluate(classif, X_train_eeg, y_train_eeg, params))\n    # print (\"Validation - \", evaluate(classif, X_val, y_val, params))\n    # print (\"Test - \", evaluate(net, X_test, y_test, params))","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:54:05.692027Z","iopub.status.idle":"2023-10-17T22:54:05.692853Z","shell.execute_reply.started":"2023-10-17T22:54:05.692569Z","shell.execute_reply":"2023-10-17T22:54:05.692591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 32\n\n# for epoch in range(10):  # loop over the dataset multiple times\n#     print (\"\\nEpoch \", epoch)\n\n#     running_loss = 0.0\n#     for i in range(int(len(X_train_eeg)/batch_size-1)):\n#         s = i*batch_size\n#         e = i*batch_size+batch_size\n\n#         inputs = (X_train_eeg[s:e])\n#         labels = torch.FloatTensor(np.array([y_train_eeg[s:e]]).T*1.0)\n\n#         # wrap them in Variable\n#         inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n\n#         # zero the parameter gradients\n#         optimizer.zero_grad()\n\n#         # forward + backward + optimize\n#         outputs = classif(inputs)\n#         loss = criterion(outputs, labels)\n#         loss.backward()\n\n\n#         optimizer.step()\n\n#         running_loss += loss.item()\n\n#     # # Validation accuracy\n#     # params = [\"acc\", \"auc\", \"fmeasure\"]\n#     # print (params)\n#     # print (\"Training Loss \", running_loss)\n#     # print (\"Train - \", evaluate(net, X_train, y_train, params))\n#     # print (\"Validation - \", evaluate(net, X_val, y_val, params))\n#     # print (\"Test - \", evaluate(net, X_test, y_test, params))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1017,"status":"ok","timestamp":1697481494355,"user":{"displayName":"Larissa Rangel de Azevedo","userId":"11239044081097926538"},"user_tz":180},"id":"t8YSdfSeuIcJ","outputId":"14ff20cf-f85b-4fce-a608-82cade025fd6","execution":{"iopub.status.busy":"2023-10-17T22:54:05.694221Z","iopub.status.idle":"2023-10-17T22:54:05.694929Z","shell.execute_reply.started":"2023-10-17T22:54:05.694684Z","shell.execute_reply":"2023-10-17T22:54:05.694706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convolution Functions","metadata":{}},{"cell_type":"code","source":"# from math import floor\n# def compute_dim_Conv2D(Hin, \n#                 kernel_size=3, \n#                 stride=1,\n#                 padding = 0,\n#                 dilation = 1\n#                 ):\n#     return floor( (Hin + (2*padding) - (dilation*(kernel_size-1)) -1)/(stride) + 1 ) \n\n# def compute_dim_TransConv2D(Hin, \n#                         kernel_size=118, \n#                         stride=1,\n#                         padding = 0,\n#                         dilation = 1,\n#                         output_padding = 0\n        \n#         ):\n#     return ((Hin - 1)*stride) - (2*padding)+ (dilation*(kernel_size - 1)) + output_padding + 1\n\n\n# def compute_maxpool_2d(Hin, \n#                         kernel_size=4, \n#                         padding = 0,\n#                         dilation = 1        \n#         ):\n\n#     stride = kernel_size\n#     return ( ( (Hin + (2*padding)-(dilation*(kernel_size - 1)) -1) / stride ) + 1)\n \n","metadata":{"execution":{"iopub.status.busy":"2023-10-17T22:54:05.696332Z","iopub.status.idle":"2023-10-17T22:54:05.697127Z","shell.execute_reply.started":"2023-10-17T22:54:05.696877Z","shell.execute_reply":"2023-10-17T22:54:05.696902Z"},"trusted":true},"execution_count":null,"outputs":[]}]}