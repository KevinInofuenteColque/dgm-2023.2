{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f8d000-1d1a-46b1-a3d0-e87f73ef5397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-15 15:53:00.749749: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 15:53:00.749778: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 15:53:00.749799: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 15:53:00.756583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import TensorDataset, \n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale as standard_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "# torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize, preprocess, Preprocessor)\n",
    "from braindecode.preprocessing import \\\n",
    "    create_windows_from_events, create_fixed_length_windows\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52145935-7225-4c08-a9a9-d8eb0c738bb0",
   "metadata": {},
   "source": [
    "# Functions and Classes for EEG DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03c552e-ccce-41ca-9f90-1c9263c17648",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocessor(\n",
    "    dataset,\n",
    "    low_cut_hz = 4.,   # low cut frequency for filtering\n",
    "    high_cut_hz = 38., # high cut frequency for filtering\n",
    "    newfreq = 100, # Paramater for resampling\n",
    "    factor = 1e6, # Parameter for scaling\n",
    "    ):\n",
    "\n",
    "    preprocessors = [\n",
    "        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "        # Preprocessor(lambda data: np.multiply(data, factor)),  # Convert from V to uV\n",
    "        Preprocessor(\"resample\", sfreq=newfreq), # Resampling\n",
    "        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\"), # Common Average Reference\n",
    "        Preprocessor(standard_scale, channel_wise=True) ## Standard Scale \n",
    "    ]\n",
    "\n",
    "    # Transform the data\n",
    "    # return preprocess(dataset, preprocessors, n_jobs = -1)\n",
    "    return preprocess(dataset, preprocessors)\n",
    "\n",
    "def get_windows(\n",
    "        dataset, \n",
    "        trial_start_offset_samples=0,\n",
    "        trial_stop_offset_samples=100,\n",
    "        window_size_samples=400,\n",
    "        window_stride_samples=100,\n",
    "        preload=True,\n",
    "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
    "        picks = ['C3', 'Cz', 'C4']\n",
    "        ):\n",
    "    \n",
    "    windows_dataset = create_windows_from_events(\n",
    "        dataset,\n",
    "        trial_start_offset_samples = trial_start_offset_samples,\n",
    "        trial_stop_offset_samples  = trial_stop_offset_samples,\n",
    "        window_size_samples        = window_size_samples,\n",
    "        window_stride_samples      = window_stride_samples,\n",
    "        preload                    = True,\n",
    "        # mapping = {'left_hand': 0, 'right_hand': 1},\n",
    "        # picks                      = picks\n",
    "        )\n",
    "\n",
    "    # preprocess(windows_dataset, [Preprocessor(standard_scale, channel_wise=True)]) ## Standard Scale window\n",
    "    \n",
    "    return windows_dataset\n",
    "\n",
    "\n",
    "def get_tensors_from_windows(windows_dataset):\n",
    "    windows_list = []\n",
    "    labels_list = []\n",
    "    n_runs = len(windows_dataset.datasets)\n",
    "    for i in range(n_runs):\n",
    "        windows_list.append(windows_dataset.datasets[i].windows.get_data())\n",
    "        labels_list.append(windows_dataset.datasets[i].y)\n",
    "        \n",
    "    stacked_tensor = np.concatenate(windows_list, axis=0)\n",
    "    stacked_labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    del windows_list,labels_list\n",
    "    \n",
    "    return stacked_tensor, stacked_labels\n",
    "\n",
    "\n",
    "class EEG(Dataset):\n",
    "\n",
    "    def __init__(self, subject_id = 3, dataset_name=\"BNCI2014_001\", transform = None):\n",
    "        \n",
    "        self.raw_dataset     = MOABBDataset(dataset_name = dataset_name, subject_ids=subject_id)\n",
    "        self.prepro_dataset  = preprocessor(self.raw_dataset)\n",
    "        self.windows_dataset = get_windows(self.prepro_dataset)\n",
    "        self.data            = get_tensors_from_windows(self.windows_dataset)\n",
    "        self.transform       = transform\n",
    "        self.classes         = self.windows_dataset.datasets[0].windows.event_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data[0].shape[0]\n",
    "\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # sample = {'signal': torch.from_numpy(self.data[0])[idx], 'label': torch.from_numpy(self.data[1])[idx]}\n",
    "        \n",
    "        sample = (torch.from_numpy(np.expand_dims(self.data[0], axis = 1))[idx], torch.from_numpy(self.data[1])[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        im_chan: the number of channels of the output eeg, a scalar\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, input_dim=68, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            #### For 3 channels\n",
    "            # self.make_gen_block(input_dim, hidden_dim * 4,      kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim * 2, hidden_dim,     kernel_size = (1,60), stride = (1,1)),\n",
    "            # self.make_gen_block(hidden_dim, im_chan,            kernel_size = (3,50), stride = (1,2), padding = (0,2), final_layer=True),\n",
    "            #### For 22 channels\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4,      kernel_size = (3,60), stride = (1,1)),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size = (4,60), stride = (3,1)),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim,     kernel_size = (3,60), stride = (2,1)),\n",
    "            self.make_gen_block(hidden_dim, im_chan,            kernel_size = (2,50), stride = (1,2), padding = (0,2), final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size, stride, padding = 0, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n",
    "        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, input_dim)\n",
    "        '''\n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0dfc26-a825-49cc-8640-47d53644e2f7",
   "metadata": {},
   "source": [
    "# Classification of the Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe41cc7d-c6b8-4066-8750-db3720f9d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "## Getting the real data\n",
    "my_eeg_data = EEG(subject_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87730745-dadf-4ca6-8207-941c5254a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_eeg_data[:][0]\n",
    "y = F.one_hot(my_eeg_data[:][1], 4)\n",
    "\n",
    "real_tensor_dataset = TensorDataset(X, y)\n",
    "train_size = int(0.8 * len(real_tensor_dataset.tensors[0]))\n",
    "test_size = len(real_tensor_dataset.tensors[0]) - train_size\n",
    "# Here we divide the datasets in test and train. The Test dataset will be used for .predict after the fit\n",
    "real_train_dataset, real_test_dataset = random_split(real_tensor_dataset, [train_size,test_size]) \n",
    "\n",
    "# Now we must divide the train dataset in train and validation for the model input\n",
    "# final_train_size = int(0.8 * len(real_train_dataset.dataset.tensors[0]))\n",
    "# final_val_size = len(real_train_dataset.dataset.tensors[0]) - train_size\n",
    "\n",
    "# real_train_dataset, real_val_dataset  = random_split(real_train_dataset, [final_train_size, final_val_size]) \n",
    "\n",
    "# ### Train test split\n",
    "# x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "# x_train = x_train.astype(\"float32\")\n",
    "# x_val = x_val.astype(\"float32\")\n",
    "\n",
    "# y_train = y_train.astype(\"float32\")\n",
    "# y_val = y_val.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2284b7e-505b-46da-88a6-f855a178ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "eegnet_model = EEGNetv4(\n",
    "    in_chans   = 22,\n",
    "    n_classes = 4,\n",
    "    input_window_samples = my_eeg_data[:][0].shape[-1],\n",
    "    final_conv_length='auto',\n",
    "    F1=8,\n",
    "    D=2,\n",
    "    F2=8*2,\n",
    "    kernel_length=64,\n",
    "    drop_prob=0.5\n",
    ")\n",
    "eegnet_model.to(device)\n",
    "\n",
    "# Creating classifier\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "real_data_classifier = EEGClassifier(\n",
    "    eegnet_model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=predefined_split(real_testset),\n",
    "    batch_size = batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
